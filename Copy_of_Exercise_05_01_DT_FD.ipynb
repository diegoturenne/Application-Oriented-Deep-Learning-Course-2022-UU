{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diegoturenne/Application-Oriented-Deep-Learning-Course-2022-UU/blob/main/Copy_of_Exercise_05_01_DT_FD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF2trPuyzm9C"
      },
      "source": [
        "# Exercise 5.1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uK90XJ2abewa",
        "outputId": "c2b6f2f2-df5f-41a2-c5d0-8666bb1b085a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    div#notebook-container    { width: 95%; }\n",
              "    div#menubar-container     { width: 65%; }\n",
              "    div#maintoolbar-container { width: 99%; }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML(data=\"\"\"\n",
        "<style>\n",
        "    div#notebook-container    { width: 95%; }\n",
        "    div#menubar-container     { width: 65%; }\n",
        "    div#maintoolbar-container { width: 99%; }\n",
        "</style>\n",
        "\"\"\"))\n",
        "\n",
        "#width for some images\n",
        "im_width = 11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipcsUFDUzm9C"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCJe_ITJzm9G"
      },
      "source": [
        "**Simple Network**\n",
        "\n",
        "We continue with the dataset first encountered in the previous exercise. Please refer to the discussion there for an introduction to the data and the learning objective.\n",
        "\n",
        "Here, we manually implement a simple network architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NopU99AT9G7s",
        "outputId": "d7e8848e-b9c0-4eb4-8f18-5acda9d8c343"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  258k  100  258k    0     0   189k      0  0:00:01  0:00:01 --:--:--  189k\n"
          ]
        }
      ],
      "source": [
        "# The code snippet below is responsible for downloading the dataset\n",
        "# - for example when running via Google Colab.\n",
        "#\n",
        "# You can also directly download the file using the link if you work\n",
        "# with a local setup (in that case, ignore the !wget)\n",
        "\n",
        "# !wget https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\n",
        "!curl -O https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ONqeI5Uzm9H",
        "outputId": "d31ba8d4-cf0a-4f25-8a93-9091c0dd041a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data: (4898, 12)\n",
            "First example:\n",
            "Features: [7.600e+00 2.400e-01 4.400e-01 3.800e+00 3.700e-02 4.900e+01 1.460e+02\n",
            " 9.911e-01 3.060e+00 3.700e-01 1.160e+01]\n",
            "Quality: 6.0\n"
          ]
        }
      ],
      "source": [
        "# Before working with the data, \n",
        "# we download and prepare all features\n",
        "\n",
        "# load all examples from the file\n",
        "data = np.genfromtxt('winequality-white.csv',delimiter=\";\",skip_header=1)\n",
        "\n",
        "print(\"data:\", data.shape)\n",
        "\n",
        "# Prepare for proper training\n",
        "np.random.shuffle(data) # randomly sort examples\n",
        "\n",
        "# take the first 3000 examples for training\n",
        "# (remember array slicing from last week)\n",
        "X_train = data[:3000,:11] # all features except last column\n",
        "y_train = data[:3000,11]  # quality column\n",
        "\n",
        "# and the remaining examples for testing\n",
        "X_test = data[3000:,:11] # all features except last column\n",
        "y_test = data[3000:,11] # quality column\n",
        "\n",
        "print(\"First example:\")\n",
        "print(\"Features:\", X_train[0])\n",
        "print(\"Quality:\", y_train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiwnyNHpzm9L"
      },
      "source": [
        "# Problems\n",
        "\n",
        "The goal is to implement the training of a neural network with one input layer, one hidden layer, and one output layer using gradient descent. We first (below) define the matrices and initialise with random values. We need W, b, W' and b'. The shapes will be:\n",
        "  * W: (number of hidden nodes, number of inputs) named `W`\n",
        "  * b: (number of hidden nodes) named `b`\n",
        "  * W': (number of hidden nodes) named `Wp`\n",
        "  * b': (one) named `bp`\n",
        "\n",
        "Your tasks are:     \n",
        "   * Implement a forward pass of the network as `dnn` (see below)\n",
        "   * Implement a function that uses one data point to update the weights using gradient descent. You can follow the `update_weights` skeleton below\n",
        "   * Now you can use the code below (training loop and evaluation) to train the network for multiple data points and even over several epochs. Try to find a set of hyperparameters (number of nodes in the hidden layer, learning rate, number of training epochs) that gives stable results. What is the best result (as measured by the loss on the training sample) you can get?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRzvovJvkQB1",
        "outputId": "d3b82658-d45c-4a84-a79f-eee8a6db2bce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(50, 11)\n"
          ]
        }
      ],
      "source": [
        "# Initialise weights with suitable random distributions\n",
        "hidden_nodes = 50 # number of nodes in the hidden layer\n",
        "n_inputs = 11 # input features in the dataset\n",
        "\n",
        "W = np.random.randn(hidden_nodes,11)*np.sqrt(2./n_inputs)\n",
        "b = np.random.randn(hidden_nodes)*np.sqrt(2./n_inputs)\n",
        "Wp = np.random.randn(hidden_nodes)*np.sqrt(2./hidden_nodes)\n",
        "bp = np.random.randn((1))\n",
        "\n",
        "print(W.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZI4TGelKkQB2"
      },
      "outputs": [],
      "source": [
        "# You can use this implementation of the ReLu activation function\n",
        "def relu(x):\n",
        "    return np.maximum(x, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzR88W_okQB2"
      },
      "outputs": [],
      "source": [
        "def dnn(x,W,b,Wp,bp):\n",
        "    # TODO Calculate and return network output of forward pass\n",
        "    # See Hint 1 for additional information\n",
        "    z1 = np.matmul(W,x) + b # weight the inputs\n",
        "    z2 = relu(z1) # non linear activation: now going away from hidden node and into ouput \n",
        "    z3 = np.matmul(Wp, z2) + bp # out from all hidden nodes into single quality\n",
        "    \n",
        "    return z3 # output: single quality number "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAMGFQH1bewk"
      },
      "outputs": [],
      "source": [
        "# # test cell for forward dnn \n",
        "# x_test_dt = X_train[100]\n",
        "# y_test_dt = y_train[100]\n",
        "\n",
        "# y_prop_test_dy = dnn(x_test_dt,W,b,Wp,bp)\n",
        "\n",
        "# y_prop_test_dy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFp4e-RhkQB3"
      },
      "outputs": [],
      "source": [
        "def update_weights(x,y, W, b, Wp, bp):\n",
        "    \n",
        "    learning_rate = 1e-5 # it's a real dick move to suggest the wrong learning rate by default.\n",
        "    # if you wanted us to choose, just say it or don't input anything.\n",
        "    \n",
        "    # TODO: Calculate the network output (use the function dnn defined above)\n",
        "    y_out = dnn(x,W, b, Wp, bp) \n",
        "    # TODO: Derive the gradient for each of W,b,Wp,bp by taking the partial\n",
        "    # derivative of the loss function with respect to the variable and\n",
        "\n",
        "    # I ended up needing to implement an ugly loop instead to some vector calculation to check the values .... \n",
        "    # As just a direct implementation of the formulas (thus the commented loops)\n",
        "    \n",
        "    sum_tmp = np.dot(W,x) + b  #calculation that is used often for the  derivatives\n",
        "\n",
        "    dL_dbp = 2*(y_out - y)  \n",
        "    \n",
        "    dL_db = dL_dbp *  Wp* np.heaviside(sum_tmp, 0.5) \n",
        "#     dL_db = np.zeros_like(b)\n",
        "#     for k in np.arange(len(b)):\n",
        "#         s = 0 \n",
        "#         for i in np.arange(len(x)):\n",
        "#             s += W[k,i]*x[i]\n",
        "#         s2 = s + b[k]\n",
        "#         dL_db[k] = dL_dbp*Wp[k]*np.heaviside(s2, 0.5)\n",
        "        \n",
        "\n",
        "    dL_dWp = dL_dbp * relu(sum_tmp)\n",
        "#     dL_dWp = np.zeros_like(Wp)\n",
        "#     for k in np.arange(len(Wp)):\n",
        "#         s = 0 \n",
        "#         for i in np.arange(len(x)):\n",
        "#             s += W[k,i]*x[i]\n",
        "#         s2 = s + b[k]\n",
        "#         dL_dWp[k] = dL_dbp*relu(s2)\n",
        "  \n",
        "    \n",
        "    dL_dW = dL_dbp* np.outer(Wp * np.heaviside(sum_tmp, 0.5) , x)      \n",
        "#     dL_dW = np.zeros_like(W)\n",
        "#     for m in np.arange(W.shape[0]):\n",
        "#         for k in np.arange(W.shape[1]):\n",
        "#             s=0\n",
        "#             for i in np.arange(len(x)):\n",
        "#                 s += W[m,i]*x[i]\n",
        "#             s2 = s + b[m]\n",
        "#             dL_dW[m,k] = dL_dbp*Wp[m]*np.heaviside(s2, 0.5)*x[k]\n",
        "            \n",
        "\n",
        "    # TODO: Update the weights/bias following the rule:  weight_new = weight_old - learning_rate * gradient    \n",
        "    bp_new = bp - learning_rate*dL_dbp\n",
        "    b_new = b - learning_rate*dL_db\n",
        "    Wp_new = Wp - learning_rate*dL_dWp\n",
        "    W_new = W - learning_rate*dL_dW\n",
        "    #.... at least it has the right shapes... \n",
        "    \n",
        "#     return dL_db\n",
        "    return W_new, b_new, Wp_new, bp_new # return the new weights\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guL8sB2ikQB3"
      },
      "source": [
        "# Training loop and evaluation below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSr8cC6-kQB4",
        "scrolled": false,
        "outputId": "8cc72b95-ee1f-4bc1-a33a-c59e60f88116"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0 Train Loss: 0.7993169364945579 Test Loss: 0.7798091883825501\n",
            "Epoch: 1 Train Loss: 0.780319875713755 Test Loss: 0.7639703616218164\n",
            "Epoch: 2 Train Loss: 0.7632282969190204 Test Loss: 0.7493125451226721\n",
            "Epoch: 3 Train Loss: 0.747741896816861 Test Loss: 0.7395026372453749\n",
            "Epoch: 4 Train Loss: 0.7384594740854185 Test Loss: 0.7322581458880436\n",
            "Epoch: 5 Train Loss: 0.734128780424642 Test Loss: 0.727539045362166\n",
            "Epoch: 6 Train Loss: 0.7319836518098473 Test Loss: 0.7263702511469026\n",
            "Epoch: 7 Train Loss: 0.7112011759763813 Test Loss: 0.7162702596404792\n",
            "Epoch: 8 Train Loss: 0.7015789965846678 Test Loss: 0.7080777199128364\n",
            "Epoch: 9 Train Loss: 0.6938591177404999 Test Loss: 0.6998914491590358\n",
            "Epoch: 10 Train Loss: 0.6895113069056811 Test Loss: 0.6950723426642893\n",
            "Epoch: 11 Train Loss: 0.6853510504796014 Test Loss: 0.6910516878948043\n",
            "Epoch: 12 Train Loss: 0.6827070654081017 Test Loss: 0.6882521232880313\n",
            "Epoch: 13 Train Loss: 0.6798426996954452 Test Loss: 0.6849535993671222\n",
            "Epoch: 14 Train Loss: 0.6771170104553714 Test Loss: 0.6818260914270499\n",
            "Epoch: 15 Train Loss: 0.6750300794998632 Test Loss: 0.6792989193902681\n",
            "Epoch: 16 Train Loss: 0.6730165049183722 Test Loss: 0.6768929951094864\n",
            "Epoch: 17 Train Loss: 0.6709117566647779 Test Loss: 0.674430625470166\n",
            "Epoch: 18 Train Loss: 0.6685378293316814 Test Loss: 0.671357241629466\n",
            "Epoch: 19 Train Loss: 0.6655955793181636 Test Loss: 0.6678348790839764\n",
            "Epoch: 20 Train Loss: 0.6642355805690956 Test Loss: 0.6656564080221048\n",
            "Epoch: 21 Train Loss: 0.6623619213806048 Test Loss: 0.6636681430196818\n",
            "Epoch: 22 Train Loss: 0.6614031185619239 Test Loss: 0.6624676931050877\n",
            "Epoch: 23 Train Loss: 0.6600607659237769 Test Loss: 0.661046408447477\n",
            "Epoch: 24 Train Loss: 0.6597129077928403 Test Loss: 0.6602896543160817\n",
            "Epoch: 25 Train Loss: 0.6576583007369787 Test Loss: 0.6584524596057065\n",
            "Epoch: 26 Train Loss: 0.6562617063329357 Test Loss: 0.6574733050985145\n",
            "Epoch: 27 Train Loss: 0.6555055310675905 Test Loss: 0.656623845041276\n",
            "Epoch: 28 Train Loss: 0.6539513703661627 Test Loss: 0.6556516191501592\n",
            "Epoch: 29 Train Loss: 0.6526863505711135 Test Loss: 0.6545850997154568\n",
            "Epoch: 30 Train Loss: 0.6521050618816224 Test Loss: 0.653917879784576\n",
            "Epoch: 31 Train Loss: 0.6506866537519531 Test Loss: 0.6527385727607445\n",
            "Epoch: 32 Train Loss: 0.6495961319911728 Test Loss: 0.6517711608999599\n",
            "Epoch: 33 Train Loss: 0.6491479473180513 Test Loss: 0.6513321127189692\n",
            "Epoch: 34 Train Loss: 0.6479824953814675 Test Loss: 0.6505833551183168\n",
            "Epoch: 35 Train Loss: 0.6469112191338475 Test Loss: 0.6497078061358607\n",
            "Epoch: 36 Train Loss: 0.6466664686262118 Test Loss: 0.6494004045338501\n",
            "Epoch: 37 Train Loss: 0.6458886578582766 Test Loss: 0.6490505865613277\n",
            "Epoch: 38 Train Loss: 0.6450980549437604 Test Loss: 0.6485643382152676\n",
            "Epoch: 39 Train Loss: 0.6443101950480589 Test Loss: 0.64807031390868\n",
            "Epoch: 40 Train Loss: 0.6440900055787626 Test Loss: 0.6478069977524328\n",
            "Epoch: 41 Train Loss: 0.6430020591530816 Test Loss: 0.646987817322952\n",
            "Epoch: 42 Train Loss: 0.641755059647259 Test Loss: 0.6460974812529636\n",
            "Epoch: 43 Train Loss: 0.6411134667073416 Test Loss: 0.6454331831416674\n",
            "Epoch: 44 Train Loss: 0.6403363863050994 Test Loss: 0.644635594965777\n",
            "Epoch: 45 Train Loss: 0.6394045968020332 Test Loss: 0.6440008782806752\n",
            "Epoch: 46 Train Loss: 0.6388132232760749 Test Loss: 0.6435487381539093\n",
            "Epoch: 47 Train Loss: 0.6378243157883906 Test Loss: 0.642867832572215\n",
            "Epoch: 48 Train Loss: 0.637006125312703 Test Loss: 0.6422951862802013\n",
            "Epoch: 49 Train Loss: 0.6362166461820074 Test Loss: 0.6417654270163745\n",
            "Epoch: 50 Train Loss: 0.6355014049967087 Test Loss: 0.6413167277654963\n",
            "Epoch: 51 Train Loss: 0.6348159840183217 Test Loss: 0.6409538889835432\n",
            "Epoch: 52 Train Loss: 0.6341968788968146 Test Loss: 0.6406611794172566\n",
            "Epoch: 53 Train Loss: 0.6334817939080282 Test Loss: 0.6402050153134661\n",
            "Epoch: 54 Train Loss: 0.6331236111034981 Test Loss: 0.6402301734449266\n",
            "Epoch: 55 Train Loss: 0.632698434686637 Test Loss: 0.6401017772026274\n",
            "Epoch: 56 Train Loss: 0.6322777191138275 Test Loss: 0.6399840443870402\n",
            "Epoch: 57 Train Loss: 0.6317712328897221 Test Loss: 0.6397938632869908\n",
            "Epoch: 58 Train Loss: 0.6313208854939824 Test Loss: 0.6394943400564995\n",
            "Epoch: 59 Train Loss: 0.6307651445017002 Test Loss: 0.6393318676260257\n",
            "Epoch: 60 Train Loss: 0.6302577813760863 Test Loss: 0.639264825725218\n",
            "Epoch: 61 Train Loss: 0.6297210101447948 Test Loss: 0.6392463052230374\n",
            "Epoch: 62 Train Loss: 0.6291701796048745 Test Loss: 0.6391294310715482\n",
            "Epoch: 63 Train Loss: 0.6285576046600011 Test Loss: 0.6389958437632794\n",
            "Epoch: 64 Train Loss: 0.6280778006070185 Test Loss: 0.638990808841104\n",
            "Epoch: 65 Train Loss: 0.6273808772975875 Test Loss: 0.6386912151758443\n",
            "Epoch: 66 Train Loss: 0.6268709992692366 Test Loss: 0.6386182352877621\n",
            "Epoch: 67 Train Loss: 0.626211394608904 Test Loss: 0.6382737953197039\n",
            "Epoch: 68 Train Loss: 0.6255881498915168 Test Loss: 0.6379704663816121\n",
            "Epoch: 69 Train Loss: 0.6251504724905735 Test Loss: 0.6380006862155462\n",
            "Epoch: 70 Train Loss: 0.6245029092050877 Test Loss: 0.6374863081136692\n",
            "Epoch: 71 Train Loss: 0.624045682986133 Test Loss: 0.63733430103087\n",
            "Epoch: 72 Train Loss: 0.6233909197929682 Test Loss: 0.6369932827691867\n",
            "Epoch: 73 Train Loss: 0.6229373985412847 Test Loss: 0.6368128838060348\n",
            "Epoch: 74 Train Loss: 0.6223604649274899 Test Loss: 0.636428083665824\n",
            "Epoch: 75 Train Loss: 0.6219260843059741 Test Loss: 0.6362718080600039\n",
            "Epoch: 76 Train Loss: 0.6213153661589177 Test Loss: 0.6358481562717878\n",
            "Epoch: 77 Train Loss: 0.6209488429147624 Test Loss: 0.6358265189119721\n",
            "Epoch: 78 Train Loss: 0.6204928622302078 Test Loss: 0.6357961168345118\n",
            "Epoch: 79 Train Loss: 0.6200606035563812 Test Loss: 0.6356949156002123\n",
            "Epoch: 80 Train Loss: 0.6195834521523387 Test Loss: 0.6356274557600586\n",
            "Epoch: 81 Train Loss: 0.6192842903450521 Test Loss: 0.635777985371036\n",
            "Epoch: 82 Train Loss: 0.618879303720792 Test Loss: 0.6358400090500091\n",
            "Epoch: 83 Train Loss: 0.6186130515491283 Test Loss: 0.6360577498383626\n",
            "Epoch: 84 Train Loss: 0.6182479960067485 Test Loss: 0.6361931422741159\n",
            "Epoch: 85 Train Loss: 0.6180123273325788 Test Loss: 0.6363617329519865\n",
            "Epoch: 86 Train Loss: 0.617569574416152 Test Loss: 0.6363080104888602\n",
            "Epoch: 87 Train Loss: 0.6172806192793888 Test Loss: 0.6364503079458758\n",
            "Epoch: 88 Train Loss: 0.6170144720425731 Test Loss: 0.6365769864470753\n",
            "Epoch: 89 Train Loss: 0.6165982321850297 Test Loss: 0.6364771653974053\n",
            "Epoch: 90 Train Loss: 0.6163548336228379 Test Loss: 0.6366534837098464\n",
            "Epoch: 91 Train Loss: 0.6159575220102911 Test Loss: 0.6366865372337146\n",
            "Epoch: 92 Train Loss: 0.6159165451569473 Test Loss: 0.6370493574119818\n",
            "Epoch: 93 Train Loss: 0.6154581163175851 Test Loss: 0.6369726155702545\n",
            "Epoch: 94 Train Loss: 0.6151912172250906 Test Loss: 0.6371182857178677\n",
            "Epoch: 95 Train Loss: 0.6147414759363079 Test Loss: 0.6372432286182186\n",
            "Epoch: 96 Train Loss: 0.6146025753696512 Test Loss: 0.6374663929377401\n",
            "Epoch: 97 Train Loss: 0.6142394843222243 Test Loss: 0.6374452420154237\n",
            "Epoch: 98 Train Loss: 0.6138677105796246 Test Loss: 0.6379173042353373\n",
            "Epoch: 99 Train Loss: 0.6140384222145329 Test Loss: 0.6386921092099936\n",
            "Epoch: 100 Train Loss: 0.6137299042154275 Test Loss: 0.6392802319627037\n",
            "Epoch: 101 Train Loss: 0.6133559302064738 Test Loss: 0.6396224457303701\n",
            "Epoch: 102 Train Loss: 0.6130274010685793 Test Loss: 0.6399813544952638\n",
            "Epoch: 103 Train Loss: 0.6128363402606927 Test Loss: 0.6405253026372025\n",
            "Epoch: 104 Train Loss: 0.6124629510931379 Test Loss: 0.6408096025006353\n",
            "Epoch: 105 Train Loss: 0.6122812176053071 Test Loss: 0.6409103328067275\n",
            "Epoch: 106 Train Loss: 0.6120716327187531 Test Loss: 0.6410104386111458\n",
            "Epoch: 107 Train Loss: 0.611802646925903 Test Loss: 0.641060820456132\n",
            "Epoch: 108 Train Loss: 0.6116475463423554 Test Loss: 0.6410061365520208\n",
            "Epoch: 109 Train Loss: 0.6115322593099696 Test Loss: 0.6412491650913696\n",
            "Epoch: 110 Train Loss: 0.6110985601836704 Test Loss: 0.6411658412475255\n",
            "Epoch: 111 Train Loss: 0.6108240845803038 Test Loss: 0.6410695241719031\n",
            "Epoch: 112 Train Loss: 0.6104562919403347 Test Loss: 0.6410231455120831\n",
            "Epoch: 113 Train Loss: 0.6101322361349264 Test Loss: 0.6410065728653533\n",
            "Epoch: 114 Train Loss: 0.6100575212026983 Test Loss: 0.6413306365768571\n",
            "Epoch: 115 Train Loss: 0.6095833967500088 Test Loss: 0.6412382835689526\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 116 Train Loss: 0.6095424355055856 Test Loss: 0.6414278685855634\n",
            "Epoch: 117 Train Loss: 0.6091372286744696 Test Loss: 0.6414940796171494\n",
            "Epoch: 118 Train Loss: 0.6088915481374608 Test Loss: 0.6417155398098688\n",
            "Epoch: 119 Train Loss: 0.6083800358984923 Test Loss: 0.6415299568238407\n",
            "Epoch: 120 Train Loss: 0.6081448264021495 Test Loss: 0.6417258438403206\n",
            "Epoch: 121 Train Loss: 0.6079787789236742 Test Loss: 0.6419126082368042\n",
            "Epoch: 122 Train Loss: 0.6078808925348598 Test Loss: 0.6420713277415657\n",
            "Epoch: 123 Train Loss: 0.6075076618033802 Test Loss: 0.6421534997882927\n",
            "Epoch: 124 Train Loss: 0.6072224668959043 Test Loss: 0.6421951522891586\n",
            "Epoch: 125 Train Loss: 0.606825467078241 Test Loss: 0.6420838672033784\n",
            "Epoch: 126 Train Loss: 0.606406143357311 Test Loss: 0.6420278034866311\n",
            "Epoch: 127 Train Loss: 0.6066240265631745 Test Loss: 0.6423902401855643\n",
            "Epoch: 128 Train Loss: 0.6059730268414703 Test Loss: 0.6420683600182708\n",
            "Epoch: 129 Train Loss: 0.6059373071068852 Test Loss: 0.6421886994946298\n",
            "Epoch: 130 Train Loss: 0.6054462593847537 Test Loss: 0.6417475482261812\n",
            "Epoch: 131 Train Loss: 0.6053259611106248 Test Loss: 0.6417805760867377\n",
            "Epoch: 132 Train Loss: 0.6049900929184376 Test Loss: 0.6417740151087337\n",
            "Epoch: 133 Train Loss: 0.6045557987502846 Test Loss: 0.6416731634860837\n",
            "Epoch: 134 Train Loss: 0.6041936975003368 Test Loss: 0.6415356248134257\n",
            "Epoch: 135 Train Loss: 0.6040516354374824 Test Loss: 0.6414019273905397\n",
            "Epoch: 136 Train Loss: 0.6035314682924098 Test Loss: 0.6411563002572994\n",
            "Epoch: 137 Train Loss: 0.6031175381304588 Test Loss: 0.6409624114031591\n",
            "Epoch: 138 Train Loss: 0.6026446325655921 Test Loss: 0.640622564198091\n",
            "Epoch: 139 Train Loss: 0.6027388122314367 Test Loss: 0.6408178500731216\n",
            "Epoch: 140 Train Loss: 0.6021017720994714 Test Loss: 0.6403020513721475\n",
            "Epoch: 141 Train Loss: 0.6017426216145354 Test Loss: 0.6401733778570088\n",
            "Epoch: 142 Train Loss: 0.6015300988750039 Test Loss: 0.6399381412701295\n",
            "Epoch: 143 Train Loss: 0.6009199665659966 Test Loss: 0.6391513749665139\n",
            "Epoch: 144 Train Loss: 0.6004615624629827 Test Loss: 0.6387223481132001\n",
            "Epoch: 145 Train Loss: 0.5998925485019312 Test Loss: 0.6381490902157\n",
            "Epoch: 146 Train Loss: 0.5994269122100252 Test Loss: 0.6382240002655065\n",
            "Epoch: 147 Train Loss: 0.5984351312386483 Test Loss: 0.6374522170895491\n",
            "Epoch: 148 Train Loss: 0.5977962875375352 Test Loss: 0.637596296980163\n",
            "Epoch: 149 Train Loss: 0.5972745979551237 Test Loss: 0.6371801406906332\n",
            "Epoch: 150 Train Loss: 0.5969664156435871 Test Loss: 0.6371794246699639\n",
            "Epoch: 151 Train Loss: 0.5968259995201387 Test Loss: 0.6371369099402474\n",
            "Epoch: 152 Train Loss: 0.5967252726722765 Test Loss: 0.6372025925718134\n",
            "Epoch: 153 Train Loss: 0.5963580048048792 Test Loss: 0.6369186621029582\n",
            "Epoch: 154 Train Loss: 0.5961546212394634 Test Loss: 0.6367353965789019\n",
            "Epoch: 155 Train Loss: 0.5959628654254329 Test Loss: 0.6364049397638473\n",
            "Epoch: 156 Train Loss: 0.595805119630224 Test Loss: 0.6367773826095228\n",
            "Epoch: 157 Train Loss: 0.5954007148687077 Test Loss: 0.6357527919119648\n",
            "Epoch: 158 Train Loss: 0.595189181358957 Test Loss: 0.6354511426828479\n",
            "Epoch: 159 Train Loss: 0.5948597586020719 Test Loss: 0.6349767455576494\n",
            "Epoch: 160 Train Loss: 0.5947294458138922 Test Loss: 0.6346164517012874\n",
            "Epoch: 161 Train Loss: 0.594452603456391 Test Loss: 0.6345908238514462\n",
            "Epoch: 162 Train Loss: 0.5942931172174313 Test Loss: 0.6343124882516068\n",
            "Epoch: 163 Train Loss: 0.593948123002016 Test Loss: 0.6340605258242525\n",
            "Epoch: 164 Train Loss: 0.5941677162831936 Test Loss: 0.6344747768309661\n",
            "Epoch: 165 Train Loss: 0.5936597591702406 Test Loss: 0.6336548507985448\n",
            "Epoch: 166 Train Loss: 0.5935091806289862 Test Loss: 0.6336373161327487\n",
            "Epoch: 167 Train Loss: 0.5932696433888257 Test Loss: 0.63391186186317\n",
            "Epoch: 168 Train Loss: 0.5931575363792867 Test Loss: 0.6335871350385999\n",
            "Epoch: 169 Train Loss: 0.5928580284440955 Test Loss: 0.6336371197309743\n",
            "Epoch: 170 Train Loss: 0.5926925796698065 Test Loss: 0.6331467644983853\n",
            "Epoch: 171 Train Loss: 0.5925372492000415 Test Loss: 0.6333788152019988\n",
            "Epoch: 172 Train Loss: 0.59251061061112 Test Loss: 0.6331009082754656\n",
            "Epoch: 173 Train Loss: 0.5922259289922692 Test Loss: 0.6332161156687518\n",
            "Epoch: 174 Train Loss: 0.591991415901729 Test Loss: 0.633003642374903\n",
            "Epoch: 175 Train Loss: 0.5919710542737002 Test Loss: 0.632878880922563\n",
            "Epoch: 176 Train Loss: 0.5916129762106818 Test Loss: 0.6325799867091527\n",
            "Epoch: 177 Train Loss: 0.5913374085066848 Test Loss: 0.6321818275716965\n",
            "Epoch: 178 Train Loss: 0.5909451352873555 Test Loss: 0.6317274792494623\n",
            "Epoch: 179 Train Loss: 0.5908355083809879 Test Loss: 0.6315474749334143\n",
            "Epoch: 180 Train Loss: 0.5906238295247362 Test Loss: 0.6313898432888456\n",
            "Epoch: 181 Train Loss: 0.5901997450444936 Test Loss: 0.6309849961276681\n",
            "Epoch: 182 Train Loss: 0.5898990592799457 Test Loss: 0.6309061109023093\n",
            "Epoch: 183 Train Loss: 0.5896598760158329 Test Loss: 0.6306422015960783\n",
            "Epoch: 184 Train Loss: 0.589198321687651 Test Loss: 0.6303438870607112\n",
            "Epoch: 185 Train Loss: 0.5889344175232349 Test Loss: 0.6302397603650209\n",
            "Epoch: 186 Train Loss: 0.5886283738316643 Test Loss: 0.630098804746413\n",
            "Epoch: 187 Train Loss: 0.5886078551162461 Test Loss: 0.6301646325118958\n",
            "Epoch: 188 Train Loss: 0.5883745056950577 Test Loss: 0.6302731283161561\n",
            "Epoch: 189 Train Loss: 0.5882202154213478 Test Loss: 0.6303349927946374\n",
            "Epoch: 190 Train Loss: 0.5879491689077438 Test Loss: 0.6301487612986778\n",
            "Epoch: 191 Train Loss: 0.5879744678627861 Test Loss: 0.6301702224195945\n",
            "Epoch: 192 Train Loss: 0.5877636610682863 Test Loss: 0.630163368063172\n",
            "Epoch: 193 Train Loss: 0.5877402801408561 Test Loss: 0.6303955781060737\n",
            "Epoch: 194 Train Loss: 0.5876633670727843 Test Loss: 0.6302942597970503\n",
            "Epoch: 195 Train Loss: 0.5874553529648657 Test Loss: 0.6302826921550887\n",
            "Epoch: 196 Train Loss: 0.5873547957175065 Test Loss: 0.6301815503085041\n",
            "Epoch: 197 Train Loss: 0.5872393614308208 Test Loss: 0.6302190658451667\n",
            "Epoch: 198 Train Loss: 0.587118170195188 Test Loss: 0.6300902872122123\n",
            "Epoch: 199 Train Loss: 0.5870663867962513 Test Loss: 0.6301937329064545\n",
            "Epoch: 200 Train Loss: 0.5868479785693899 Test Loss: 0.6300178440529557\n",
            "Epoch: 201 Train Loss: 0.5865970614208045 Test Loss: 0.6299429387704286\n",
            "Epoch: 202 Train Loss: 0.5867249608041115 Test Loss: 0.6299995757631133\n",
            "Epoch: 203 Train Loss: 0.5864688260073027 Test Loss: 0.6299179961440521\n",
            "Epoch: 204 Train Loss: 0.5862790424653012 Test Loss: 0.629855122861821\n",
            "Epoch: 205 Train Loss: 0.5862605288176196 Test Loss: 0.6298545392046143\n",
            "Epoch: 206 Train Loss: 0.5860836035683306 Test Loss: 0.6297950159678753\n",
            "Epoch: 207 Train Loss: 0.5858951131638168 Test Loss: 0.6297270613698975\n",
            "Epoch: 208 Train Loss: 0.5858835767861834 Test Loss: 0.6296505272047351\n",
            "Epoch: 209 Train Loss: 0.5856580355084965 Test Loss: 0.6294901600600485\n",
            "Epoch: 210 Train Loss: 0.585617073397213 Test Loss: 0.6295946983241172\n",
            "Epoch: 211 Train Loss: 0.5855226792608393 Test Loss: 0.6294011418067011\n",
            "Epoch: 212 Train Loss: 0.585304506850358 Test Loss: 0.6293122454106519\n",
            "Epoch: 213 Train Loss: 0.585285505102122 Test Loss: 0.6293217289549193\n",
            "Epoch: 214 Train Loss: 0.5851549176484698 Test Loss: 0.6291602702069222\n",
            "Epoch: 215 Train Loss: 0.584998988311598 Test Loss: 0.6294206723830852\n",
            "Epoch: 216 Train Loss: 0.5850411560376575 Test Loss: 0.6293749663420423\n",
            "Epoch: 217 Train Loss: 0.5849379375220893 Test Loss: 0.6290708955312349\n",
            "Epoch: 218 Train Loss: 0.5847306936019371 Test Loss: 0.6289019862629432\n",
            "Epoch: 219 Train Loss: 0.5844817838685656 Test Loss: 0.628775442226739\n",
            "Epoch: 220 Train Loss: 0.584242911471388 Test Loss: 0.6288822561497163\n",
            "Epoch: 221 Train Loss: 0.584116780737013 Test Loss: 0.6286900921850627\n",
            "Epoch: 222 Train Loss: 0.5840277110613 Test Loss: 0.6284557449049658\n",
            "Epoch: 223 Train Loss: 0.5839361423944659 Test Loss: 0.6289074281666182\n",
            "Epoch: 224 Train Loss: 0.5837742981642129 Test Loss: 0.6285193453201323\n",
            "Epoch: 225 Train Loss: 0.5836191319068083 Test Loss: 0.6283800652859403\n",
            "Epoch: 226 Train Loss: 0.583669647421609 Test Loss: 0.6282615973657669\n",
            "Epoch: 227 Train Loss: 0.583486596242513 Test Loss: 0.6283522369664645\n",
            "Epoch: 228 Train Loss: 0.5835507928878946 Test Loss: 0.6285897243006402\n",
            "Epoch: 229 Train Loss: 0.5833108809797553 Test Loss: 0.6281795852945125\n",
            "Epoch: 230 Train Loss: 0.5834266467342593 Test Loss: 0.6288395758328098\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 231 Train Loss: 0.5831594963883685 Test Loss: 0.6283747414929556\n",
            "Epoch: 232 Train Loss: 0.5831736292359044 Test Loss: 0.628341428514906\n",
            "Epoch: 233 Train Loss: 0.583089300763453 Test Loss: 0.628156041871777\n",
            "Epoch: 234 Train Loss: 0.5831023867110812 Test Loss: 0.6282685080175372\n",
            "Epoch: 235 Train Loss: 0.5829245487703901 Test Loss: 0.6279736927060445\n",
            "Epoch: 236 Train Loss: 0.5830143618257327 Test Loss: 0.6280736918537758\n",
            "Epoch: 237 Train Loss: 0.5828477730208004 Test Loss: 0.6282226691700608\n",
            "Epoch: 238 Train Loss: 0.5827068438941813 Test Loss: 0.6279201481892152\n",
            "Epoch: 239 Train Loss: 0.5826986849289933 Test Loss: 0.6280709872754638\n",
            "Epoch: 240 Train Loss: 0.5825419390158338 Test Loss: 0.6277398245589396\n",
            "Epoch: 241 Train Loss: 0.5824625076071414 Test Loss: 0.6276689408746767\n",
            "Epoch: 242 Train Loss: 0.5823081018596493 Test Loss: 0.6277425743403602\n",
            "Epoch: 243 Train Loss: 0.5824598548957571 Test Loss: 0.6277258217648032\n",
            "Epoch: 244 Train Loss: 0.5822167289187352 Test Loss: 0.6278435578224429\n",
            "Epoch: 245 Train Loss: 0.5821476667454456 Test Loss: 0.6276763743121014\n",
            "Epoch: 246 Train Loss: 0.582095382323016 Test Loss: 0.6275147107211186\n",
            "Epoch: 247 Train Loss: 0.5818903644728014 Test Loss: 0.6269670542153906\n",
            "Epoch: 248 Train Loss: 0.5820569625471069 Test Loss: 0.6275942115015906\n",
            "Epoch: 249 Train Loss: 0.5817410144008927 Test Loss: 0.627100671202794\n",
            "Epoch: 250 Train Loss: 0.5817958788415859 Test Loss: 0.6274099097774886\n",
            "Epoch: 251 Train Loss: 0.581675287363133 Test Loss: 0.6272000714960414\n",
            "Epoch: 252 Train Loss: 0.5812505199559483 Test Loss: 0.6265440183839913\n",
            "Epoch: 253 Train Loss: 0.5815868006396534 Test Loss: 0.6272694147800519\n",
            "Epoch: 254 Train Loss: 0.5812691884657656 Test Loss: 0.6266935364553398\n",
            "Epoch: 255 Train Loss: 0.5810791225942498 Test Loss: 0.6270159044605152\n",
            "Epoch: 256 Train Loss: 0.5811362675463211 Test Loss: 0.626676100244179\n",
            "Epoch: 257 Train Loss: 0.5809956500801896 Test Loss: 0.6270287916895747\n",
            "Epoch: 258 Train Loss: 0.5808247720237402 Test Loss: 0.6264381107600105\n",
            "Epoch: 259 Train Loss: 0.5807483010677552 Test Loss: 0.6268911543236151\n",
            "Epoch: 260 Train Loss: 0.5805746425379289 Test Loss: 0.6263111451011346\n",
            "Epoch: 261 Train Loss: 0.5805484965384143 Test Loss: 0.6266700911759264\n",
            "Epoch: 262 Train Loss: 0.5804097311724687 Test Loss: 0.6263023884370166\n",
            "Epoch: 263 Train Loss: 0.5801659362137792 Test Loss: 0.6263796353792696\n",
            "Epoch: 264 Train Loss: 0.5800612423497057 Test Loss: 0.6259762537004578\n",
            "Epoch: 265 Train Loss: 0.5798889465463317 Test Loss: 0.6260453471166985\n",
            "Epoch: 266 Train Loss: 0.5799636176892152 Test Loss: 0.6265423694812461\n",
            "Epoch: 267 Train Loss: 0.5796876181271975 Test Loss: 0.6258873982059004\n",
            "Epoch: 268 Train Loss: 0.5795474561522247 Test Loss: 0.6260849865633712\n",
            "Epoch: 269 Train Loss: 0.5793783894460459 Test Loss: 0.6256281528722335\n",
            "Epoch: 270 Train Loss: 0.5792617815742583 Test Loss: 0.6255793530646875\n",
            "Epoch: 271 Train Loss: 0.5792512005176276 Test Loss: 0.6254343302347408\n",
            "Epoch: 272 Train Loss: 0.5790984048344219 Test Loss: 0.6257045691656453\n",
            "Epoch: 273 Train Loss: 0.5789804193653582 Test Loss: 0.6253423274229901\n",
            "Epoch: 274 Train Loss: 0.5787895364920796 Test Loss: 0.6254283123177916\n",
            "Epoch: 275 Train Loss: 0.5787748181293235 Test Loss: 0.6258258782852965\n",
            "Epoch: 276 Train Loss: 0.578624100325931 Test Loss: 0.6253935912982918\n",
            "Epoch: 277 Train Loss: 0.5785582239771072 Test Loss: 0.6254756102066539\n",
            "Epoch: 278 Train Loss: 0.5785553884314484 Test Loss: 0.6253117050895376\n",
            "Epoch: 279 Train Loss: 0.578435509351795 Test Loss: 0.6255439619811047\n",
            "Epoch: 280 Train Loss: 0.5783205321866998 Test Loss: 0.6252333537388136\n",
            "Epoch: 281 Train Loss: 0.5782020245569466 Test Loss: 0.6253411783840893\n",
            "Epoch: 282 Train Loss: 0.5782541794541675 Test Loss: 0.625394286398764\n",
            "Epoch: 283 Train Loss: 0.5780619449612392 Test Loss: 0.6252740289300347\n",
            "Epoch: 284 Train Loss: 0.578047906199553 Test Loss: 0.6250194777330031\n",
            "Epoch: 285 Train Loss: 0.5778504010253039 Test Loss: 0.6251413642307709\n",
            "Epoch: 286 Train Loss: 0.5780139699046477 Test Loss: 0.6253320232751993\n",
            "Epoch: 287 Train Loss: 0.5776341729612411 Test Loss: 0.6253533761074892\n",
            "Epoch: 288 Train Loss: 0.5774591167164818 Test Loss: 0.6253940847173811\n",
            "Epoch: 289 Train Loss: 0.5773928709553553 Test Loss: 0.6249431692946459\n",
            "Epoch: 290 Train Loss: 0.5770973545993018 Test Loss: 0.6247383021297067\n",
            "Epoch: 291 Train Loss: 0.5770063669603868 Test Loss: 0.6250592392921334\n",
            "Epoch: 292 Train Loss: 0.5769693170518188 Test Loss: 0.6251732753238286\n",
            "Epoch: 293 Train Loss: 0.5769084340180748 Test Loss: 0.6248672745886974\n",
            "Epoch: 294 Train Loss: 0.5767422631936722 Test Loss: 0.6253387698414408\n",
            "Epoch: 295 Train Loss: 0.5766090768186036 Test Loss: 0.6248518799513112\n",
            "Epoch: 296 Train Loss: 0.5765349063336175 Test Loss: 0.6250827402248117\n",
            "Epoch: 297 Train Loss: 0.576396928216488 Test Loss: 0.6247487892662899\n",
            "Epoch: 298 Train Loss: 0.5764459085661118 Test Loss: 0.625143577342444\n",
            "Epoch: 299 Train Loss: 0.5762061256892493 Test Loss: 0.6247941342495087\n",
            "Epoch: 300 Train Loss: 0.5762499248228935 Test Loss: 0.6250605052637002\n",
            "Epoch: 301 Train Loss: 0.5760903348095916 Test Loss: 0.6247313158964836\n",
            "Epoch: 302 Train Loss: 0.5760184329769192 Test Loss: 0.6248822616278246\n",
            "Epoch: 303 Train Loss: 0.5760637787443508 Test Loss: 0.6251237157108532\n",
            "Epoch: 304 Train Loss: 0.5758500265382467 Test Loss: 0.6251448125068811\n",
            "Epoch: 305 Train Loss: 0.575912082235854 Test Loss: 0.6249842182779914\n",
            "Epoch: 306 Train Loss: 0.5758184687022437 Test Loss: 0.6250942414112072\n",
            "Epoch: 307 Train Loss: 0.5759683559692361 Test Loss: 0.6251298100102768\n",
            "Epoch: 308 Train Loss: 0.5756742711844695 Test Loss: 0.6251070382074062\n",
            "Epoch: 309 Train Loss: 0.5755676471444727 Test Loss: 0.6249475647490447\n",
            "Epoch: 310 Train Loss: 0.5757554925985127 Test Loss: 0.625503246129329\n",
            "Epoch: 311 Train Loss: 0.5754208852957166 Test Loss: 0.624945909677804\n",
            "Epoch: 312 Train Loss: 0.5754704655224463 Test Loss: 0.6247855574886438\n",
            "Epoch: 313 Train Loss: 0.5752738308092845 Test Loss: 0.6249781537605795\n",
            "Epoch: 314 Train Loss: 0.5754228181113613 Test Loss: 0.6250251005779379\n",
            "Epoch: 315 Train Loss: 0.5751653247721098 Test Loss: 0.6250883432329053\n",
            "Epoch: 316 Train Loss: 0.5751402402742957 Test Loss: 0.6249701957274094\n",
            "Epoch: 317 Train Loss: 0.5752529210569786 Test Loss: 0.6252098034577863\n",
            "Epoch: 318 Train Loss: 0.5750811812056903 Test Loss: 0.6253661573524102\n",
            "Epoch: 319 Train Loss: 0.5750035323690299 Test Loss: 0.6251578848433987\n",
            "Epoch: 320 Train Loss: 0.5749173252553246 Test Loss: 0.6256801744094966\n",
            "Epoch: 321 Train Loss: 0.5747013195117061 Test Loss: 0.6253109003507757\n",
            "Epoch: 322 Train Loss: 0.5748047574080742 Test Loss: 0.6253394461688053\n",
            "Epoch: 323 Train Loss: 0.5746191911489866 Test Loss: 0.6253266493306694\n",
            "Epoch: 324 Train Loss: 0.5748475189007028 Test Loss: 0.6256092130460411\n",
            "Epoch: 325 Train Loss: 0.5745605774503848 Test Loss: 0.6252628850179078\n",
            "Epoch: 326 Train Loss: 0.5744331640076803 Test Loss: 0.6256127105502427\n",
            "Epoch: 327 Train Loss: 0.5745609174487891 Test Loss: 0.626007355859491\n",
            "Epoch: 328 Train Loss: 0.5743423807586296 Test Loss: 0.6255965359849474\n",
            "Epoch: 329 Train Loss: 0.5743478057325876 Test Loss: 0.6259548282932038\n",
            "Epoch: 330 Train Loss: 0.5743538939420819 Test Loss: 0.6258689630419164\n",
            "Epoch: 331 Train Loss: 0.5741519472150041 Test Loss: 0.625555789972709\n",
            "Epoch: 332 Train Loss: 0.5742401166700287 Test Loss: 0.6256557920706718\n",
            "Epoch: 333 Train Loss: 0.5741326906597203 Test Loss: 0.6258146332363854\n",
            "Epoch: 334 Train Loss: 0.5741476685968928 Test Loss: 0.6260543098883148\n",
            "Epoch: 335 Train Loss: 0.5740916562019567 Test Loss: 0.625840354175213\n",
            "Epoch: 336 Train Loss: 0.5739572524719381 Test Loss: 0.6259827543422262\n",
            "Epoch: 337 Train Loss: 0.574014184659134 Test Loss: 0.6262743864382174\n",
            "Epoch: 338 Train Loss: 0.5738350908225405 Test Loss: 0.6256685865432989\n",
            "Epoch: 339 Train Loss: 0.573833986709867 Test Loss: 0.6256201503842355\n",
            "Epoch: 340 Train Loss: 0.5737664427976986 Test Loss: 0.626232777748183\n",
            "Epoch: 341 Train Loss: 0.5735533819362684 Test Loss: 0.6256526627066261\n",
            "Epoch: 342 Train Loss: 0.5736624347591763 Test Loss: 0.6257259110399762\n",
            "Epoch: 343 Train Loss: 0.5736203237023795 Test Loss: 0.625893095627217\n",
            "Epoch: 344 Train Loss: 0.5736724812857087 Test Loss: 0.6260992814942031\n",
            "Epoch: 345 Train Loss: 0.5735607717777675 Test Loss: 0.6256127331755619\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 346 Train Loss: 0.5734299029356207 Test Loss: 0.6259888540119644\n",
            "Epoch: 347 Train Loss: 0.5734923756801228 Test Loss: 0.6260487277881023\n",
            "Epoch: 348 Train Loss: 0.5732690021728946 Test Loss: 0.6257191123961815\n",
            "Epoch: 349 Train Loss: 0.5734076951811578 Test Loss: 0.6255046917482311\n",
            "Epoch: 350 Train Loss: 0.5732484412103671 Test Loss: 0.6258812117863873\n",
            "Epoch: 351 Train Loss: 0.5730258505792275 Test Loss: 0.6253881005013807\n",
            "Epoch: 352 Train Loss: 0.5731970893032465 Test Loss: 0.6256083612183925\n",
            "Epoch: 353 Train Loss: 0.5730671474316149 Test Loss: 0.6256236867603348\n",
            "Epoch: 354 Train Loss: 0.5731068225215329 Test Loss: 0.6257524629448432\n",
            "Epoch: 355 Train Loss: 0.5730004376080627 Test Loss: 0.6255419073974694\n",
            "Epoch: 356 Train Loss: 0.5730004097046654 Test Loss: 0.6252543812584859\n",
            "Epoch: 357 Train Loss: 0.5729343204315523 Test Loss: 0.625865914761819\n",
            "Epoch: 358 Train Loss: 0.5728353382558173 Test Loss: 0.6253833458277522\n",
            "Epoch: 359 Train Loss: 0.572778198681987 Test Loss: 0.6253748231926963\n",
            "Epoch: 360 Train Loss: 0.5727959849236638 Test Loss: 0.6256800991609781\n",
            "Epoch: 361 Train Loss: 0.5727114494419808 Test Loss: 0.6253372533115444\n",
            "Epoch: 362 Train Loss: 0.5726396883645302 Test Loss: 0.6253058133817876\n",
            "Epoch: 363 Train Loss: 0.5726621944581534 Test Loss: 0.6256348431922364\n",
            "Epoch: 364 Train Loss: 0.5724199306927482 Test Loss: 0.6253887587715644\n",
            "Epoch: 365 Train Loss: 0.5724855963277855 Test Loss: 0.6250664039781628\n",
            "Epoch: 366 Train Loss: 0.5725991889427627 Test Loss: 0.6255126928193655\n",
            "Epoch: 367 Train Loss: 0.5724000441196434 Test Loss: 0.6249159217714425\n",
            "Epoch: 368 Train Loss: 0.5722329904954132 Test Loss: 0.6252388389126202\n",
            "Epoch: 369 Train Loss: 0.5725054282324413 Test Loss: 0.6253844819865376\n",
            "Epoch: 370 Train Loss: 0.5722223505967082 Test Loss: 0.6248559372875186\n",
            "Epoch: 371 Train Loss: 0.5721644003167644 Test Loss: 0.625289738618846\n",
            "Epoch: 372 Train Loss: 0.5722308086837754 Test Loss: 0.6252537927877823\n",
            "Epoch: 373 Train Loss: 0.5720219455722594 Test Loss: 0.6247596782749887\n",
            "Epoch: 374 Train Loss: 0.5719256740100218 Test Loss: 0.6247115775734405\n",
            "Epoch: 375 Train Loss: 0.5720635357259236 Test Loss: 0.625133683640943\n",
            "Epoch: 376 Train Loss: 0.5718537458491966 Test Loss: 0.6246495824877243\n",
            "Epoch: 377 Train Loss: 0.57196050064054 Test Loss: 0.6245209236198689\n",
            "Epoch: 378 Train Loss: 0.5718303229755606 Test Loss: 0.6251763017561764\n",
            "Epoch: 379 Train Loss: 0.5717053478330588 Test Loss: 0.6246318203972472\n",
            "Epoch: 380 Train Loss: 0.5718297390446124 Test Loss: 0.6245007378376174\n",
            "Epoch: 381 Train Loss: 0.5716970608594432 Test Loss: 0.6246513533687605\n",
            "Epoch: 382 Train Loss: 0.5717850626168689 Test Loss: 0.6245847188243342\n",
            "Epoch: 383 Train Loss: 0.5716340844815821 Test Loss: 0.6242138551517343\n",
            "Epoch: 384 Train Loss: 0.5716496005768796 Test Loss: 0.6244039011759155\n",
            "Epoch: 385 Train Loss: 0.5716962664473472 Test Loss: 0.6244765663575512\n",
            "Epoch: 386 Train Loss: 0.5714945214550895 Test Loss: 0.6242840804353376\n",
            "Epoch: 387 Train Loss: 0.5715836688237999 Test Loss: 0.6240934103875132\n",
            "Epoch: 388 Train Loss: 0.5714948621621359 Test Loss: 0.6243955764972807\n",
            "Epoch: 389 Train Loss: 0.5712687880796326 Test Loss: 0.6242235132881581\n",
            "Epoch: 390 Train Loss: 0.5713778773147022 Test Loss: 0.6240022533939513\n",
            "Epoch: 391 Train Loss: 0.5713258191121313 Test Loss: 0.6242801575849577\n",
            "Epoch: 392 Train Loss: 0.571016477100391 Test Loss: 0.6240845012519516\n",
            "Epoch: 393 Train Loss: 0.5712500207791851 Test Loss: 0.6239990869356854\n",
            "Epoch: 394 Train Loss: 0.5711373911118063 Test Loss: 0.6239774147210113\n",
            "Epoch: 395 Train Loss: 0.5712077823170452 Test Loss: 0.6244494403002913\n",
            "Epoch: 396 Train Loss: 0.5711322162294659 Test Loss: 0.6238770740967127\n",
            "Epoch: 397 Train Loss: 0.571101577463801 Test Loss: 0.6239449585097379\n",
            "Epoch: 398 Train Loss: 0.5709488733483102 Test Loss: 0.6242504874639174\n",
            "Epoch: 399 Train Loss: 0.571012616221733 Test Loss: 0.6238552408591596\n",
            "Epoch: 400 Train Loss: 0.5708749361412465 Test Loss: 0.6238285112807316\n",
            "Epoch: 401 Train Loss: 0.5707172656245407 Test Loss: 0.6237713503623705\n",
            "Epoch: 402 Train Loss: 0.5710558000908691 Test Loss: 0.6240509154448908\n",
            "Epoch: 403 Train Loss: 0.5708843372699564 Test Loss: 0.6234429349381062\n",
            "Epoch: 404 Train Loss: 0.5707219411607556 Test Loss: 0.6239783925754686\n",
            "Epoch: 405 Train Loss: 0.5708080187541456 Test Loss: 0.6239891447896283\n",
            "Epoch: 406 Train Loss: 0.5707645721109711 Test Loss: 0.6235237674789041\n",
            "Epoch: 407 Train Loss: 0.5706283754788675 Test Loss: 0.6235613549415494\n",
            "Epoch: 408 Train Loss: 0.5707177234942021 Test Loss: 0.6238941063325519\n",
            "Epoch: 409 Train Loss: 0.5704267059927641 Test Loss: 0.6232936655547346\n",
            "Epoch: 410 Train Loss: 0.5704934861261609 Test Loss: 0.6233054178160484\n",
            "Epoch: 411 Train Loss: 0.5704162357076886 Test Loss: 0.6235949614764343\n",
            "Epoch: 412 Train Loss: 0.5702380282239682 Test Loss: 0.6234160213667169\n",
            "Epoch: 413 Train Loss: 0.5703243858910814 Test Loss: 0.6232475120786497\n",
            "Epoch: 414 Train Loss: 0.5704079870463662 Test Loss: 0.623816962379115\n",
            "Epoch: 415 Train Loss: 0.5700203606154444 Test Loss: 0.6233335319080258\n",
            "Epoch: 416 Train Loss: 0.5701489340125792 Test Loss: 0.6232276194307582\n",
            "Epoch: 417 Train Loss: 0.5700848421398497 Test Loss: 0.623291248764934\n",
            "Epoch: 418 Train Loss: 0.5700356128599002 Test Loss: 0.6235606887981642\n",
            "Epoch: 419 Train Loss: 0.5699832459354006 Test Loss: 0.6231913434184928\n",
            "Epoch: 420 Train Loss: 0.5698878520516019 Test Loss: 0.623221091048455\n",
            "Epoch: 421 Train Loss: 0.5699594848651903 Test Loss: 0.6232993998613278\n",
            "Epoch: 422 Train Loss: 0.5700787901298147 Test Loss: 0.6233852251055072\n",
            "Epoch: 423 Train Loss: 0.569732921025994 Test Loss: 0.6230421486047335\n",
            "Epoch: 424 Train Loss: 0.5698092887741613 Test Loss: 0.6234282293907452\n",
            "Epoch: 425 Train Loss: 0.5697222667394636 Test Loss: 0.6230530841908675\n",
            "Epoch: 426 Train Loss: 0.5695331178542734 Test Loss: 0.6230251082935581\n",
            "Epoch: 427 Train Loss: 0.5694834037761596 Test Loss: 0.623277211122724\n",
            "Epoch: 428 Train Loss: 0.5695467222960401 Test Loss: 0.62335641912897\n",
            "Epoch: 429 Train Loss: 0.5696395348191672 Test Loss: 0.6230796041527078\n",
            "Epoch: 430 Train Loss: 0.5696135363102024 Test Loss: 0.6227468674675313\n",
            "Epoch: 431 Train Loss: 0.5695794818966804 Test Loss: 0.6231751453840392\n",
            "Epoch: 432 Train Loss: 0.5692592436832529 Test Loss: 0.6229073767598007\n",
            "Epoch: 433 Train Loss: 0.56942659023132 Test Loss: 0.6227404246109672\n",
            "Epoch: 434 Train Loss: 0.5694849610255603 Test Loss: 0.6231706653582587\n",
            "Epoch: 435 Train Loss: 0.5692525059607577 Test Loss: 0.6227548794937406\n",
            "Epoch: 436 Train Loss: 0.5692324596617175 Test Loss: 0.6227242078353337\n",
            "Epoch: 437 Train Loss: 0.569113278375221 Test Loss: 0.6228495455328029\n",
            "Epoch: 438 Train Loss: 0.5692773257114198 Test Loss: 0.6230238618390251\n",
            "Epoch: 439 Train Loss: 0.5691670484274898 Test Loss: 0.6227430980579042\n",
            "Epoch: 440 Train Loss: 0.5691750185766297 Test Loss: 0.6228970923339376\n",
            "Epoch: 441 Train Loss: 0.569130289313384 Test Loss: 0.6229376529492897\n",
            "Epoch: 442 Train Loss: 0.5689096593646285 Test Loss: 0.6226947899609623\n",
            "Epoch: 443 Train Loss: 0.5690398518195935 Test Loss: 0.6225106589185466\n",
            "Epoch: 444 Train Loss: 0.568880225156021 Test Loss: 0.623045933114167\n",
            "Epoch: 445 Train Loss: 0.5687733005729304 Test Loss: 0.6224982421292252\n",
            "Epoch: 446 Train Loss: 0.5688213574232239 Test Loss: 0.6223496795383434\n",
            "Epoch: 447 Train Loss: 0.5687813104144904 Test Loss: 0.6227881657519005\n",
            "Epoch: 448 Train Loss: 0.5689859842733684 Test Loss: 0.622761973384286\n",
            "Epoch: 449 Train Loss: 0.5686636227473078 Test Loss: 0.6225389783088433\n",
            "Epoch: 450 Train Loss: 0.5686386208223705 Test Loss: 0.6224759794812468\n",
            "Epoch: 451 Train Loss: 0.5687778422317558 Test Loss: 0.6227906165163759\n",
            "Epoch: 452 Train Loss: 0.5686178006481264 Test Loss: 0.6223076506274706\n",
            "Epoch: 453 Train Loss: 0.5685125254697803 Test Loss: 0.6223010703413648\n",
            "Epoch: 454 Train Loss: 0.5684774104904472 Test Loss: 0.6224119697198239\n",
            "Epoch: 455 Train Loss: 0.5686554087690183 Test Loss: 0.6225920269678452\n",
            "Epoch: 456 Train Loss: 0.5684696945201307 Test Loss: 0.6222907097743002\n",
            "Epoch: 457 Train Loss: 0.5684886716046998 Test Loss: 0.6224128404057756\n",
            "Epoch: 458 Train Loss: 0.5685610117213403 Test Loss: 0.6224826594313606\n",
            "Epoch: 459 Train Loss: 0.5683312628330682 Test Loss: 0.6222114757432249\n",
            "Epoch: 460 Train Loss: 0.5683131337670722 Test Loss: 0.6221593240351365\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 461 Train Loss: 0.568281895236531 Test Loss: 0.6226668415211019\n",
            "Epoch: 462 Train Loss: 0.5682620394327806 Test Loss: 0.6221445297922353\n",
            "Epoch: 463 Train Loss: 0.568272851337897 Test Loss: 0.6218074260834483\n",
            "Epoch: 464 Train Loss: 0.5680591777090959 Test Loss: 0.6221958300582315\n",
            "Epoch: 465 Train Loss: 0.5681612346658194 Test Loss: 0.6224171655477498\n",
            "Epoch: 466 Train Loss: 0.5682551337874775 Test Loss: 0.6220645663470493\n",
            "Epoch: 467 Train Loss: 0.568119047373241 Test Loss: 0.6220532975794895\n",
            "Epoch: 468 Train Loss: 0.5681364439856816 Test Loss: 0.6221481052842937\n",
            "Epoch: 469 Train Loss: 0.5680436621099033 Test Loss: 0.6218519690980342\n",
            "Epoch: 470 Train Loss: 0.5680235587930013 Test Loss: 0.6218726408129522\n",
            "Epoch: 471 Train Loss: 0.5679313416761369 Test Loss: 0.6218588545304491\n",
            "Epoch: 472 Train Loss: 0.567997808135778 Test Loss: 0.6220641308180527\n",
            "Epoch: 473 Train Loss: 0.5678473889649011 Test Loss: 0.6216988293047163\n",
            "Epoch: 474 Train Loss: 0.5677386767199655 Test Loss: 0.621773083904899\n",
            "Epoch: 475 Train Loss: 0.5678090825252917 Test Loss: 0.6217477066889623\n",
            "Epoch: 476 Train Loss: 0.5679056089430151 Test Loss: 0.6222242932499743\n",
            "Epoch: 477 Train Loss: 0.5677413790773573 Test Loss: 0.6217427709123454\n",
            "Epoch: 478 Train Loss: 0.5677495197886065 Test Loss: 0.6216494015248505\n",
            "Epoch: 479 Train Loss: 0.5678195608269356 Test Loss: 0.6219757881419727\n",
            "Epoch: 480 Train Loss: 0.5676242305018174 Test Loss: 0.6217828094398758\n",
            "Epoch: 481 Train Loss: 0.5674875319268399 Test Loss: 0.6217111758255314\n",
            "Epoch: 482 Train Loss: 0.5675280631373116 Test Loss: 0.621719651938932\n",
            "Epoch: 483 Train Loss: 0.5675345690510814 Test Loss: 0.6221728459344558\n",
            "Epoch: 484 Train Loss: 0.5674060675970226 Test Loss: 0.6216007162192272\n",
            "Epoch: 485 Train Loss: 0.5675503431693444 Test Loss: 0.6213469239204383\n",
            "Epoch: 486 Train Loss: 0.5675981682983199 Test Loss: 0.6219320732824305\n",
            "Epoch: 487 Train Loss: 0.5672546645404828 Test Loss: 0.621658354318043\n",
            "Epoch: 488 Train Loss: 0.5673505830853739 Test Loss: 0.6213005566779418\n",
            "Epoch: 489 Train Loss: 0.5672620996940749 Test Loss: 0.6214814027254519\n",
            "Epoch: 490 Train Loss: 0.5674101744116724 Test Loss: 0.621591061320483\n",
            "Epoch: 491 Train Loss: 0.567248794484275 Test Loss: 0.6212183860771741\n",
            "Epoch: 492 Train Loss: 0.5672458792774604 Test Loss: 0.6210865257863538\n",
            "Epoch: 493 Train Loss: 0.5672379108692116 Test Loss: 0.6215722316571751\n",
            "Epoch: 494 Train Loss: 0.5670320307334538 Test Loss: 0.6212090136025092\n",
            "Epoch: 495 Train Loss: 0.5670871532598688 Test Loss: 0.6211615633338411\n",
            "Epoch: 496 Train Loss: 0.5671930170797203 Test Loss: 0.6214055106328046\n",
            "Epoch: 497 Train Loss: 0.5670082345276044 Test Loss: 0.621142507411154\n",
            "Epoch: 498 Train Loss: 0.5669851262562923 Test Loss: 0.6208425449639876\n",
            "Epoch: 499 Train Loss: 0.5669977851310845 Test Loss: 0.6207440978455863\n",
            "Best loss: 0.6207440978455863 Final loss: 0.6207440978455863\n",
            "Correlation coefficient: 0.47201098289551785\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAuCUlEQVR4nO3deXhc1Z3u+++vSlUqqTSPtiTj2YAB24AhJBACoRkMCUPSYerQuemcS0gnNOl0OIHuTvKkb/c5ye3TuYTOQEKazMClQziQxkkcCFOYjAEDHvEQ25JlW/MsVamq1vljlY0QZSPbKpUsvZ/n0VNVu/Yu/ZYfqFdrrb3XNuccIiIiowVyXYCIiExOCggREclIASEiIhkpIEREJCMFhIiIZJSX6wLGU1VVlZszZ06uyxAROWa8/PLLbc656kzvTamAmDNnDmvWrMl1GSIixwwz23mw9zTEJCIiGSkgREQkIwWEiIhkNKXmIEREDtfw8DBNTU0MDQ3lupSsikQiNDQ0EAqFxnyMAkJEprWmpiaKi4uZM2cOZpbrcrLCOUd7eztNTU3MnTt3zMdldYjJzC4xs81mttXMbsvwfqmZ/drMXjOz9Wb2ybEeKyIyHoaGhqisrJyy4QBgZlRWVh52LylrAWFmQeA7wApgMXCdmS0etdtngQ3OuaXAecC/mVl4jMeKiIyLqRwO+x1JG7PZgzgT2Oqc2+6ciwP3A1eM2scBxeYrLwI6gMQYjx03dz6+hafebM3Wx4uIHJOyGRD1QOOI103pbSN9GzgRaAbeAG5xzqXGeCwAZnajma0xszWtrUf2Jf/9p7bxjAJCRHKgq6uL7373u4d93KWXXkpXV9f4FzRCNgMiU39m9N2JLgbWAnXAMuDbZlYyxmP9Rud+4Jxb7pxbXl2d8Wrxd1UQzmNwOHlEx4qIHI2DBUQyeejvpJUrV1JWVpalqrxsnsXUBMwa8boB31MY6ZPA152/rd1WM/sTcMIYjx03BeGAAkJEcuK2225j27ZtLFu2jFAoRFFRETNnzmTt2rVs2LCBK6+8ksbGRoaGhrjlllu48cYbgbeWFurr62PFihWcc845PPfcc9TX1/Pwww9TUFBw1LVlMyBeAhaa2VxgN3AtcP2ofXYBFwDPmFktcDywHegaw7HjpiAUZDCugBCZ7r726/VsaO4Z189cXFfCVz980kHf//rXv866detYu3YtTz75JJdddhnr1q07cDrqPffcQ0VFBYODg5xxxhl89KMfpbKy8m2fsWXLFu677z7uvvturr76ah588EE+/vGPH3XtWQsI51zCzD4H/A4IAvc459ab2U3p9+8C/h/gx2b2Bn5Y6UvOuTaATMdmq9aCUFA9CBGZFM4888y3Xatw55138tBDDwHQ2NjIli1b3hEQc+fOZdmyZQCcfvrp7NixY1xqyeqFcs65lcDKUdvuGvG8GbhorMdmS0Q9CBGBQ/6lP1Gi0eiB508++SSPPfYYzz//PIWFhZx33nkZr2XIz88/8DwYDDI4ODgutWgtJqAgHGRIPQgRyYHi4mJ6e3szvtfd3U15eTmFhYVs2rSJF154YUJr01IbQGE4SHOXAkJEJl5lZSVnn302J598MgUFBdTW1h5475JLLuGuu+5iyZIlHH/88Zx11lkTWpsCAj/ENKAhJhHJkXvvvTfj9vz8fH7zm99kfG//PENVVRXr1q07sP2LX/ziuNWlISb8JLWGmERE3k4BgU5zFRHJRAGBn6QeHE7ir9cTERFQQAB+DiLlIJ5M5boUEZFJQwGBP4sJYCiugBAR2U8BgZ+DABgYTuS4EhGRyUMBgZ+DADRRLSIT7kiX+wa44447GBgYGOeK3qKAAC5cdSG3BB/UekwiMuEmc0DoQjkglOij3Hp1LYSITLiRy31feOGF1NTU8MADDxCLxbjqqqv42te+Rn9/P1dffTVNTU0kk0m+/OUvs2/fPpqbmzn//POpqqriiSeeGPfaFBBAKhQlyhCDmqQWmd5+cxvsfWN8P3PGKbDi6wd9e+Ry36tWreKXv/wlq1evxjnH5ZdfztNPP01rayt1dXU8+uijgF+jqbS0lG9+85s88cQTVFVVjW/NaRpiAlyokEIb0hCTiOTUqlWrWLVqFaeeeiqnnXYamzZtYsuWLZxyyik89thjfOlLX+KZZ56htLR0QupRDwIgXESUGN1xncUkMq0d4i/9ieCc4/bbb+fTn/70O957+eWXWblyJbfffjsXXXQRX/nKV7Jej3oQgIWjFNqQ5iBEZMKNXO774osv5p577qGvrw+A3bt309LSQnNzM4WFhXz84x/ni1/8Iq+88so7js0G9SAAyy8iSpNOcxWRCTdyue8VK1Zw/fXX8973vheAoqIifv7zn7N161ZuvfVWAoEAoVCI733vewDceOONrFixgpkzZ2qSOluCkSIKGWJwWJPUIjLxRi/3fcstt7zt9fz587n44ovfcdzNN9/MzTffnLW6NMQEBPKLiFpMk9QiIiMoIAALFxFFcxAiIiMpIADyiyiwGIOxeK4rEZEcmA5L/R9JGxUQAOEoARyJ2GCuKxGRCRaJRGhvb5/SIeGco729nUgkcljHaZIaIBwFwMX6clyIiEy0hoYGmpqaaG1tzXUpWRWJRGhoaDisYxQQAOEiAFy8P8eFiMhEC4VCzJ07N9dlTEoaYoK3ehBx9SBERPZTQMCBgLBh9SBERPZTQMCBIaaAhphERA5QQMCBHkRgOHs33hAROdYoIOCtgEioByEisp8CAg4MMeUl1IMQEdlPAQEHehD5qUHiCS3YJyICCggvL0KKgL+rnJb8FhEBFBCeGYm8QqLEGBjWXeVERCDLAWFml5jZZjPbama3ZXj/VjNbm/5ZZ2ZJM6tIv7fDzN5Iv7cmm3UCJPMKiTJIf0w9CBERyOJSG2YWBL4DXAg0AS+Z2SPOuQ3793HO/Svwr+n9Pwz8rXOuY8THnO+ca8tWjSOlQlGiNsSA7kstIgJktwdxJrDVObfdORcH7geuOMT+1wH3ZbGeQ3KhKIXE1IMQEUnLZkDUA40jXjelt72DmRUClwAPjtjsgFVm9rKZ3XiwX2JmN5rZGjNbc1SrMYajFNmgehAiImnZDAjLsO1gC65/GHh21PDS2c6504AVwGfN7NxMBzrnfuCcW+6cW15dXX3k1RaUUcIA/TqLSUQEyG5ANAGzRrxuAJoPsu+1jBpecs41px9bgIfwQ1ZZEywsp8z66BkczuavERE5ZmQzIF4CFprZXDML40PgkdE7mVkp8AHg4RHbomZWvP85cBGwLou1EiquopxeugZ021EREcjiWUzOuYSZfQ74HRAE7nHOrTezm9Lv35Xe9SpglXNu5EJItcBDZra/xnudc7/NVq0AedFK8myY3r7ebP4aEZFjRlbvKOecWwmsHLXtrlGvfwz8eNS27cDSbNb2DgXlAMR7JuSsWhGRSU9XUu9XWAFAor89x4WIiEwOCoj90j0I19/xLjuKiEwPCoj9CnwPwoa6cluHiMgkoYDYL1oFQDimISYREVBAvCVaTYoApcl2neoqIoIC4i2BIMMFVdTQxZaWvlxXIyKScwqIEay4lhrr4s19uhZCREQBMUKotI6ZgS42NPfkuhQRkZxTQIxgxTOoy+vmsY37SKUOtq6giMj0oIAYqaSekmQXXT29bNYwk4hMcwqIkSrnYzhm2z56h3RfCBGZ3hQQI1UuAGCe7WFoWPeFEJHpTQEx0oGAaCaWSOW4GBGR3FJAjJRfRLxsPpcHnycWG8p1NSIiOaWAGKX3jL/hhEAjkbb1uS5FRCSnFBCjWNVC/zikVV1FZHpTQIwSKqoEIKBVXUVkmlNAjBIu9gGRN9SZ40pERHJLATFKOFpOyhnBWFeuSxERySkFxCgWzKOHQkLx7lyXIiKSUwqIDHqsiPCwAkJEpjcFRAa9VqyAEJFpTwGRQX+gmIKElvwWkelNAZFBX6CUaKIr12WIiOSUAiKDnrxyipM6zVVEpjcFRAb9eeVE3BDE+3NdiohIziggMugPVaSftOa2EBGRHFJAZBDP3x8QbbktREQkhxQQmURr/GNfS27rEBHJIQVEBsFiHxBOQ0wiMo0pIDLIL/EBEevam+NKRERyRwGRQXFxET2ukHjPvlyXIiKSMwqIDMoLw7S5EpK9GmISkelLAZFBeTREOyWapBaRaS2rAWFml5jZZjPbama3ZXj/VjNbm/5ZZ2ZJM6sYy7HZ5HsQpQQHdZqriExfWQsIMwsC3wFWAIuB68xs8ch9nHP/6pxb5pxbBtwOPOWc6xjLsdlUEQ3T7koIDbVP1K8UEZl0stmDOBPY6pzb7pyLA/cDVxxi/+uA+47w2HFVEgnRYWVEhrsgOTxRv1ZEZFLJZkDUA40jXjelt72DmRUClwAPHsGxN5rZGjNb09o6PpPKgYDRnV+H4aBz57h8pojIsSabAWEZtrmD7Pth4FnnXMfhHuuc+4Fzbrlzbnl1dfURlJlZV3Suf9K6adw+U0TkWJLNgGgCZo143QA0H2Tfa3lreOlwj82KwdIF/knb5on8tSIik0Y2A+IlYKGZzTWzMD4EHhm9k5mVAh8AHj7cY7OpuKScfVRCqwJCRKanvGx9sHMuYWafA34HBIF7nHPrzeym9Pt3pXe9CljlnOt/t2OzVWsm1cX5bE7VU9O6OeN4l4jIVJe1gABwzq0EVo7adteo1z8GfjyWYydSQ3kBW1N1nNP6FJZKQUDXFIrI9DKmbz0zi5pZIP18kZldbmah7JaWWwtri9ni6gkkBqGnKdfliIhMuLH+Wfw0EDGzeuBx4JNk+Kt/KllYW8SbqQb/Yu8buS1GRCQHxhoQ5pwbAD4C/Ltz7ir8Fc5TVkkkRFvxiSQsBLteyHU5IiITbswBYWbvBf4CeDS9LavzF5PB7BmVbA4uVECIyLQ01oD4PH6tpIfSZyLNA57IWlWTxKKaIp6NL8A1vwrDg7kuR0RkQo0pIJxzTznnLnfOfSM9Wd3mnPubLNeWc4tqi3khsQhLDcPul3NdjojIhBrrWUz3mlmJmUWBDcBmM7s1u6Xl3uK6El5OLfIvdj2f22JERCbYWIeYFjvneoAr8dcmHAfckK2iJovFM0vIi1awNzwHdr2Y63JERCbUWAMilL7u4UrgYefcMAdfeG/KCASM9y+s4rnhBbim1ZBK5bokEZEJM9aA+D6wA4gCT5vZbKAnW0VNJucuquaZ2EJsqBv26XoIEZk+xjpJfadzrt45d6nzdgLnZ7m2SeH9C6v5Y+pk/2LblD9xS0TkgLFOUpea2Tf335jHzP4N35uY8qqL86meOZudeXNg2x9yXY6IyIQZ6xDTPUAvcHX6pwf4UbaKmmzOXVTN72Mn4XY9D/H+dz9ARGQKGGtAzHfOfTV9j+jtzrmvAfOyWdhkcu6iKp5MLsGScdj5XK7LERGZEGMNiEEzO2f/CzM7G5g2lxYvn13B+rzFDFtYw0wiMm2MdT2lm4Cfpu/+BtAJfCI7JU0+4bwA71lYz5rtJ3LWtj/oBkIiMi2M9Sym15xzS4ElwBLn3KnAB7Na2SRz+bI6Ho+fjLVugu7duS5HRCTrDus2ac65nvQV1QBfyEI9k9YHT6jh5bxT/QsNM4nINHA099GcViMtkVCQuScup4NiUju1LpOITH1HExBTfqmN0S46eQavJecxuEsru4rI1HfIgDCzXjPryfDTC9RNUI2TxvsXVrOe+RR0boH4QK7LERHJqkMGhHOu2DlXkuGn2Dk35e8oN1o0P4/OqtMIkITtT+a6HBGRrDqaIaZpqXDR+XS4IoZf/89clyIiklUKiMN04SkNrEy+Bzat1LIbIjKlKSAO05KGMprqVxBKDZFce1+uyxERyRoFxBE4/dwP80LqRJK//xr07st1OSIiWaGAOALnn1DDz6r+FhcfJPZfX8x1OSIiWaGAOAJ5wQCfv+ZS/j15FfmbH6F/m1Z4FZGpRwFxhBbWFlN/8d/S5yK0/OF7uS5HRGTcKSCOwrXnnMhvwhcxd/cjuC2/z3U5IiLjSgFxFMyMwff/PRtTsxj+z/8bevbkuiQRkXGjgDhKV793EXeU/z2J2ADxB/4KkolclyQiMi4UEEcpEgpy+w1X8JXkXxFueg4e+jS4abeOoYhMQVkNCDO7xMw2m9lWM7vtIPucZ2ZrzWy9mT01YvsOM3sj/d6abNZ5tOZURbGl13FH8mOw7pfw+gO5LklE5KhlbcE9MwsC3wEuBJqAl8zsEefchhH7lAHfBS5xzu0ys5pRH3O+c64tWzWOp89fuIiPvXk15ydeZ8mjX8Dyi+CEy3JdlojIEctmD+JMYKtzbrtzLg7cD1wxap/rgV8553YBOOdaslhPVtWXFfDN607nrwf/mtbwLHjgE1rxVUSOadkMiHqgccTrpvS2kRYB5Wb2pJm9bGZ/OeI9B6xKb7/xYL/EzG40szVmtqa1tXXcij8SZ82r5JSTTuGijr+jq/A4+OmVPih0D2sROQZlMyAy3ZJ09OxtHnA6cBlwMfBlM1uUfu9s59xpwArgs2Z2bqZf4pz7gXNuuXNueXV19TiVfuS+8edLOHnecVzc+SU6TvssbFkF33svPPNvmrwWkWNKNgOiCZg14nUD0Jxhn9865/rTcw1PA0sBnHPN6ccW4CH8kNWkV1oQ4v+7ZhlD4XKu2HQBGy5/FOqXw+P/BH/451yXJyIyZtkMiJeAhWY218zCwLXAI6P2eRh4v5nlmVkh8B5go5lFzawYwMyiwEXAuizWOq6qi/P51rXLiCdSXPNgKxsv+BGc9pfwzP+CF7+f6/JERMYkawHhnEsAnwN+B2wEHnDOrTezm8zspvQ+G4HfAq8Dq4EfOufWAbXAH83stfT2R51zv81Wrdlw3vE1PPiZ9xEN53HDPS/x+Lzb4PjL4DdfgjU/0nCTiEx65qbQF9Xy5cvdmjWT65KJN/f1csN/vEhrb4xHPr2ck5/5DGx7HE75GFzxHcjLz3WJIjKNmdnLzrnlGd9TQGRf9+AwF/zbU9SVRfjVp88k77lvwRP/DA1nwFXfh8r5uS7xLc6BmX+M9ULvXmh+1b/X/ArsWw9D3RAI+psllc+GeedDpBSqF8HMZVBYkdMmiMjYKSAmgV+/1szN973KZafM5I5rlxHa9DA8cgskY3DGf4NlfwEV8yAUmbiiUkl45Sew9XHoboTBTuhugoJyCOZD76hzCvIKYOYSHwYDHRAqgM4d/tj9LAjzz4fyObDkGh+ClumENhGZDBQQk8TdT2/nX1Zu5IazZvNPV5yE9TT7M5tevx9cCgJ5UHMiLLwIZi6Folr/U3ac/4t9PG17wp9Z1fyKD6aK+RCO+t8V7/dhUbnAv65b5uurPhHywm//HOcg3gfDQ9C60YfNugffCo3S4+D6+6H2pPGtX0TGhQJiEvmXRzdw9zN/4r+dM5d//NBiv7FtKzS9BO1boHE17HwOXPKtg4pmwNxz/bzFrDOhoOzoinjph/Do3/kv7wu+DEuuPrrPy2SgAzb+Gp78nz5wzvoMLL0OKuaO/+8SkSOmgJhEnHN89ZH1/PT5nXzz6qV85LSGd+402OX/Au/b54d8tj/p/zKP9UBhJZxyNSy9BupOPfQvSyb8Mbue95/TuRP2vAY7/wiLVsDHfpz9Ia3OnX6F213P+9ezz4bakyEYgoUXQs1Jvob84uzWISIZKSAmmeFkihv+40Ve3tnJ9/7idP5sce27HzTU44Ni7b2w9TFIDcOMU/w4f2kDhIuh7c0RE8k90NP09s/IK/ATycdfBu//gv+SngjO+R7S6rth1wsQ64ZEDBJD/v3aU+D/+rWf+xCRCaWAmIR6hoa54YcvsnFPL9++/lQuOmnG2A8e6IDX7odXfw4t69/+Xkm9D478En+GUbgIqk94a04jMEluATI8CJtX+gsHG1/0E9/vu9mfEVVY4WsNR3NdpciUp4CYpLoHh/nL/3iR13d38/kLFnHzBxcQCBzGGT/O+dNQBzv8qacV86F4DL2RyaZ5LTz21bevfls+1wdb+Ww/JFV9PBTVQNlsnRUlMo4UEJPYYDzJPzz0Br96dTdnzqngf3zkZBbUTMPxeOf8vMv2p/xZUHte80Ew0P72/cpmw8kfgXP+1vc6ROSoKCAmOecc/7mmiX9ZuZGBeILPnb+Qz31wAcHD6U1MVcND8Ken/MT9UJeff9nyex8O8z4AS66F2e87+jO7RKYpBcQxorU3xj/91wZ+/Voz5y6q5s5rl1FWGH73A6eb3a/4uYttj0N/q79+ZM45/rqN3r2Qlz4rqm2Lfywoh3AhBEL+uo5gyG8rrIDiOiipg0hJrlslkhMKiGPMvS/u4quPrGNGaYTvf3w5i+v05ZVRfMBPcG9/0t93o3s3FM/w110kBqF0FqQS/qK/WK9/PjyQ+bPyS3xQJON+33nn+bmPwkp/TUrZbDjuvdCzG3r3QKwPFlwwcWeCiWSJAuIY9MquTv7656/QNRjnGx9dwhXLRt+MTw5bKuXDwiX940A79DT7L/2eZn+tSDIOBRU+cAY7Dv15gTx/lljxDB9WpfUw6z1+7mSoG6oWQU36YshoNVQt9CEVKsh+W0XGSAFxjGrtjfHZX7zC6h0dfPLsOfz9pScSCk6S01SnulTKX2TYtdPPfwx2QOtm/+U+0A7FM31PomePf88C0LXL7xPI86foDnVl/uzyOf4ixnChP1Or4Qy/xlUy4cNr7rmTO0SGB33QdfzJLzQ50AFls3zPK1Toe2m68PGYoYA4hg0nU/yPlRv50bM7OHtBJf/rY0uZWTqJvzymu2TCr5tlBvs2wMs/gmiN/+J/7t/92VoV86Bj28GHu4JhOH6F/yKO1kDLBr9GVzjqh8KCIYhW+SG0rl3+i/mkq6B9Gwy0+UUYZ5wMibi/Sr24Drp3+aALBH1vZ89r6dV3l/p5G5eCPa/7lXtDEX89Tetmvxjj3jd8XRXz/GPbZh+ILuUvvkwM+utW+va91YaK+b7NlQv9kvbJuJ8Tmv0+37sqm+17ccW1vt6iGj9HFMyD4y/1V+DXngR7X/dX3+vU5qxRQEwBD6xp5KsPr6cokse3rlnG+xZU5bokORrO+S/N/lZ/VXnjah8Y8T5/1fneN/xcylC3D4ZkAuK9E1yk+S/umhN9yHTt9AFVtcCv2tu71wdIMu5PEAgX+ppLZ8G2P/hhu/xif9JA1y5ffyDkA254wD9PDb97GWWz/ePMpf7q+7LZ/vjyuTDc7x8bX/RzRokhv17Z/vDq3eOH/Qba/JBfMOQDqb/VDw2KAmKqeHNfLzf97GV2dgxw2yUn8Klz5h7ehXVy7Nl/fw7ww17x9DBO507/JVc+x/cgNq/0X+TDg5Ac9sNbiZgf7or3+i/wSKl/HQz7L8nuRr9/+Rz/JV97kv/scFH6CzZ9M6vx+Os9Efe9l0DwrXAE347OHb530vyqP8tsyyofNP0t/mSAQBAwv55X8Qxo3+p7MPuXahmr4jofwGZ+KZo55/jQK6lP1xTzoVJzgu89Vczz/x7RKl9P/Wl+SDFU4HtHRelajr/Ut6GoJv17Zvqz5GI9ECkDnA96C0zK07EVEFNIXyzBF/7/tazasI8z51Rw53WnMqN0Au8hIZJryWEfdH0t/ou4u9H3VDp3+lOX29708yL71kPDcj9M1d/qezHFM/3zWK8PyXDUD71FSn1vY7DDh2b1CdCy0YfGkQjk+XmaQMgHSjLuw6Zirp+7qT3J11x9gu+JVR/vw6qvJd0TGvS9tcbVsODPfOCf+GE/LDfjFH9CReUC346jvEGXAmKKcc7x4Cu7+erD68gPBfm7ixZxzfJZ5GkCW2T8DKTPYov3+S/8rkY/GT/Y6b/c923wAdKyyX/BJ2LQt9ffaTEv3/dUknG/f0+zD4Khbv8Fv/8Mur59frhudBDtn+M5FAv6nkztKXDCpXDuf/dzOIdJATFFvbmvl3/83+tY/acOjq8t5h8/dCLvX1id67JE5HA453sOoQI/nBbr872CgQ4/Z7LzOb8mWdNLvlfR9JIPBzPfK9nxRx9Cn33hiH69AmIKc87x23V7+Z+/2cSujgFOn13O9Wcex+XL6nRKrMh0kYi/826PY6SAmAZiiST3vriLnz2/k+1t/cyrjvJXZ8/lqlPrieYffrdTRKYHBcQ04pzjsY0tfOvxN1m3u4fiSB5/fnoDH1pSx+mzdUMeEXk7BcQ05JzjlV1d3P30dn67fi8A719YxQ1nzeaCE2u1UqyIAAqIaa93aJifvbCT7z+1ne7BYaqKwsytivLR0xq4fFkdhWENQYlMVwoIAfw8xeMbW3hgTSO72gfY3tZPcX4eHzmtnj8/fRYn15dgWtJAZFpRQMg7OOdYs7OTX7ywk5Vv7CWeTHFcRSErTpnBR09rYFGtFlsTmQ4UEHJInf1xfr9hH4++sYdnt7aRSDnev7CKixbXcsWp9ZREdM8DkalKASFj1tkf5xcv7uTnL+xib88QZvDhJXV87oML1KsQmYIUEHJEnt/Wzm/X7eFXr+ymP55g6awyzpxbwafOnktNidZ/EpkKFBByVNr6Yvz0uR08u62dtY1d5AWMK5fVc0pDKdeeoTWgRI5lCggZNzvb+/nW41v41Su7AYiEAnzivXO4+oxZzK8uynF1InK4FBAy7vpiCZ55s5X7X2rk6S2tGHD50jpuvmChgkLkGKKAkKxq64tx9zPb+elzO4klklxzxnF8bHkDyxrKdEMjkUnuUAGR1cFjM7vEzDab2VYzu+0g+5xnZmvNbL2ZPXU4x8rkUFWUz+0rTuSPXzqfT7xvDg+saeQj332OT/3kJV7d1Znr8kTkCGWtB2FmQeBN4EKgCXgJuM45t2HEPmXAc8AlzrldZlbjnGsZy7GZqAcxOWxr7eNXrzTxo2d3MBBPct2Zx/HVDy8mEgrmujQRGSVXPYgzga3Oue3OuThwP3DFqH2uB37lnNsF4JxrOYxjZZKaX13ErRefwAt/fwGf/sA87lu9i8u//Ue2tvTlujQROQzZDIh6oHHE66b0tpEWAeVm9qSZvWxmf3kYxwJgZjea2RozW9Pa2jpOpct4KImEuH3Fifz0r86kvS/Op37yEm19R3iPXxGZcNkMiEyzk6PHs/KA04HLgIuBL5vZojEe6zc69wPn3HLn3PLqat1uczI6d1E1d91wOnu7h7ji28/y8Nrd7Gzvz3VZIvIusrnOcxMwa8TrBqA5wz5tzrl+oN/MngaWjvFYOYacMaeCX970Pj533yvccv9aAE47roxzF1XzoSUzWVCjZTxEJptsTlLn4SeaLwB24year3fOrR+xz4nAt/G9hzCwGrgW2PRux2aiSerJL5FMsWFPD89ubWflG3tY19yNActnV3Dh4louXFzLnKporssUmTZydh2EmV0K3AEEgXucc/9iZjcBOOfuSu9zK/BJIAX80Dl3x8GOfbffp4A49rT1xfjZ8zv53fq9bNrbC0B5YYizF1Rx5bJ6ls8pp6zwyG7GLiLvThfKyTGhsWOAR15r5tmtbazZ2Uk8kSJgfnhq+ZxyTqkvZUlDGXVlBbkuVWTKUEDIMWdoOMnrTd08s6WVxze28Oa+XhIp/9/qBxZV8+lz57F8TgXhPC0UKHI0FBByzBsaTrJxTw/PbGnjJ8/toL0/TiQU4Orls/jUOXOZXal5C5EjoYCQKWUwnuSJzS38YVML//vV3SSd46OnNXD50jpOqiuhsig/1yWKHDMUEDJl7eke5AdPb+f+1Y0MDicJGCybVcbsyigLaoqYWRphSUMZc6uiBLVwoMg7KCBkyusZGub1xm5e2tHB01taaeocpLX3rau28/MCLKot5sSZxcwoLeA9cytYWFtETbHujCfTmwJCpqWh4SQ72wd4vamLzXt7Wd/cw7rd3fTHE6Tnu6mMhllcV0JDeSFLG0qZVVFIZVGYOZVRLS4o08KhAiKbV1KL5FQkFOT4GcUcP+PtV2l39MfZ0NzDuuZutrb0sXFPD681dnHf6l0H9gkFjVNnlfOB46s5ub6UhTVF1JZENEwl04oCQqadimiYcxZWcc7CqgPbkilHc9cgO9sH6BiIs765m2febONff7f5HcfWFOczozTCcRWFFISDVBflU1dWwHEVhcyuLKQ4EproJolkhYaYRA6hoz/Om/t62by3l9beGPt6htjdNUhz1yBdg8MMxJLEk6m3HVOcn0dJQYhFtUXMKC1gZmmEGSURTpxZQnEkT0uJyKSiISaRI1QRDXPWvErOmleZ8f3hZIreoQSNHQPs6R5kW2s/TZ2DdPTHaOoc5PWmbtr74287ZmZphNqSCCfVlXByfSkn1ZWwqLZYcx4y6SggRI5CKBigIhqmIhpm6ayyjPvEEn6y/JktbcQTfrHClp4hHlnbzC9e9PMeeQGjvryAqqJ8zllQxUl1JcwsLeD4GcW6WlxyRgEhkmX5eUEW1RazqPbtk+WplKOxc+DA2VU72wdo6hzgzj9sYf/IbzgvQF1phIbyQmaURqgrK6C2JJ+ZpRFmlhZQUhCiXmtTSZYoIERyJBAwZldGmV0Z5dJTZh7Y3hdLsK2lj8bOAV5r7GJvT4xd7f1sa+1jX8/QgVN09zvtuDJOPa6ck+pKqCrKZ35NEXWlEcx0xpUcHU1SixxDhoaTtPfHD5xxtb21j9V/6uCN3d3EEm9NlhdH8qiMhpldGaW2JJ/yaJi60gICAaOsIERdWQEzSiPUFueTF9QQ1nSmSWqRKSISClJfVkB9WQFnzKk4sH04mWJXxwBtvTG2tPSxaW8P+3pi7O4cZH1zN50DwyRHdz3w13vk5wWZXVlIysGCmiJmVxQysyxC31CCZbPKyA8FmVkaobQgRH5eQD2TaUQBITIFhIIB5lcXMb+6iPdkOOMqkUzR3h9nOJmiuWuIfT1D7OkeZF9PjK6BYdr7/bIkaxs7WfnGnoxhYuZvFl8cCVEZDVNVlE9lUZhZFYVEQkEioQBF+XmUFoSojOYzvyZKfl6QwnBQwXKMUkCITAN5wQC1JX7dqYbywkPuO5xMsbd7CDPYsq+PvliCnqFh9nQN4XD0DiVo74/T1hvjzX29PLZxH8PJQw9VBwNGeWGI8sIw5dEwlVH/WBDyAVJaEKKqKJ+5VVEqi3z4AAqWHFNAiMjbhIIBZlX4EHm3MAE/LxIKBognUvTHE+ztHqK9P87Wlj4SyRSJlGMgnqBzYJiOvjgdA3G2tPTR2R+nP54gnki9Y+J9v6L8vAPDYKUF/gr16uJ8SgtDzCyJUFYY8vvk+d5LfVkBM8sKGBpOMhhPsqCmCFDQHCkFhIgclf0X+BWEgxSEgwf++v/AouoxHd87NEzXgP9p6R2ivS9OW3+MRNLR1hcjnkgRT6ToGUrgnKOlN8a21j7a++PEE6l3/wX4uZY5lVGKI34ILBIKMq86SmE4j2g4SH4oSDgYYG51lPLCMFVFYQLpQInmT9+vyenbchGZFIojIYojIWZVAJSO+TjnHHu6h0imHKFggJ6hYZq7BtnTPcRgPEl5NERz1xCJpKO9P0ZjxwDDSR8wjR0D/Gbd3jH9nvqyAgbiCeZXF1EQ9kGSHwowo6SAokgeM0oitPXFqCrKp6Y4n8JwkLqyAnqGhiktCFEYzqO6+Ni8iZUCQkSOSWZG3YiLBGeURt5xMeLBJFOOlPM//bEkg8NJdncO0hfzPZnW3hhm0DeUYOPeXorz89jdNUhfzA+JDcST/G79PlLOMZYrBcJ5AUIBozwaJhQMYAZV0XxKCvIoLQhTWRQmlR5nyw8FKC8MM7+miIAZAQPDmF1ZSDyZoqIwTEE4SCQUxDmX1aEzBYSITDvBgBHEf7Hm5/khssO9It05x9Bwio6BOFVFYba19DM4nGQgnmBP9xD5eQGGk472vhgdA3ESSUdT5wB5gQDJlKNzIM7uriE27umltS9GwCDlfHhlOotstJJIHvFkipmlBVREwzz4mfcd/j/Eu1BAiIgcATOjIBykPuyDZXFdyRF/VirlMAPn/OnELb0xmjoHSCQdKQft/TF6hxIEzeiNJegeHKazP04wYLT3xymOZOerXAEhIpJjgfSNqPaPFtWWRA6clpxLusZeREQyUkCIiEhGCggREclIASEiIhkpIEREJCMFhIiIZKSAEBGRjBQQIiKS0ZS65aiZtQI7j/DwKqBtHMs5FqjN04PaPD0caZtnO+cyLr07pQLiaJjZmoPdl3WqUpunB7V5eshGmzXEJCIiGSkgREQkIwXEW36Q6wJyQG2eHtTm6WHc26w5CBERyUg9CBERyUgBISIiGU37gDCzS8xss5ltNbPbcl3PeDGze8ysxczWjdhWYWa/N7Mt6cfyEe/dnv432GxmF+em6qNjZrPM7Akz22hm683slvT2KdtuM4uY2Wozey3d5q+lt0/ZNu9nZkEze9XM/iv9ekq32cx2mNkbZrbWzNakt2W3zc65afsDBIFtwDwgDLwGLM51XePUtnOB04B1I7b9v8Bt6ee3Ad9IP1+cbns+MDf9bxLMdRuOoM0zgdPSz4uBN9Ntm7LtBgwoSj8PAS8CZ03lNo9o+xeAe4H/Sr+e0m0GdgBVo7Zltc3TvQdxJrDVObfdORcH7geuyHFN48I59zTQMWrzFcBP0s9/Alw5Yvv9zrmYc+5PwFb8v80xxTm3xzn3Svp5L7ARqGcKt9t5femXofSPYwq3GcDMGoDLgB+O2Dyl23wQWW3zdA+IeqBxxOum9LapqtY5twf8lylQk94+5f4dzGwOcCr+L+op3e70UMtaoAX4vXNuyrcZuAP470BqxLap3mYHrDKzl83sxvS2rLY57yiKnQosw7bpeN7vlPp3MLMi4EHg8865HrNMzfO7Zth2zLXbOZcElplZGfCQmZ18iN2P+Tab2YeAFufcy2Z23lgOybDtmGpz2tnOuWYzqwF+b2abDrHvuLR5uvcgmoBZI143AM05qmUi7DOzmQDpx5b09inz72BmIXw4/MI596v05infbgDnXBfwJHAJU7vNZwOXm9kO/LDwB83s50ztNuOca04/tgAP4YeMstrm6R4QLwELzWyumYWBa4FHclxTNj0CfCL9/BPAwyO2X2tm+WY2F1gIrM5BfUfFfFfhP4CNzrlvjnhryrbbzKrTPQfMrAD4M2ATU7jNzrnbnXMNzrk5+P9n/+Cc+zhTuM1mFjWz4v3PgYuAdWS7zbmemc/1D3Ap/myXbcA/5LqecWzXfcAeYBj/18SngErgcWBL+rFixP7/kP432AysyHX9R9jmc/Dd6NeBtemfS6dyu4ElwKvpNq8DvpLePmXbPKr95/HWWUxTts34My1fS/+s3/9dle02a6kNERHJaLoPMYmIyEEoIEREJCMFhIiIZKSAEBGRjBQQIiKSkQJC5DCYWTK9mub+n3FbAdjM5oxcfVck16b7Uhsih2vQObcs10WITAT1IETGQXqt/m+k782w2swWpLfPNrPHzez19ONx6e21ZvZQ+j4Or5nZ+9IfFTSzu9P3dliVvjpaJCcUECKHp2DUENM1I97rcc6dCXwbv9oo6ec/dc4tAX4B3JnefifwlHNuKf6+HevT2xcC33HOnQR0AR/NamtEDkFXUoscBjPrc84VZdi+A/igc257esHAvc65SjNrA2Y654bT2/c456rMrBVocM7FRnzGHPxy3QvTr78EhJxz/zwBTRN5B/UgRMaPO8jzg+2TSWzE8ySaJ5QcUkCIjJ9rRjw+n37+HH7FUYC/AP6Yfv448Bk4cMOfkokqUmSs9NeJyOEpSN+9bb/fOuf2n+qab2Yv4v/wui697W+Ae8zsVqAV+GR6+y3AD8zsU/iewmfwq++KTBqagxAZB+k5iOXOubZc1yIyXjTEJCIiGakHISIiGakHISIiGSkgREQkIwWEiIhkpIAQEZGMFBAiIpLR/wHOqOvHsrg5mwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 10s, sys: 1.99 s, total: 1min 12s\n",
            "Wall time: 1min 10s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# The code below implements the training.\n",
        "# If you correctly implement  dnn and update_weights above, \n",
        "# you should not need to change anything below. \n",
        "# (apart from increasing the number of epochs)\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "\n",
        "# How many epochs to train\n",
        "# This will just train for one epoch\n",
        "# You will want a higher number once everything works\n",
        "n_epochs = 500\n",
        "\n",
        "# Loop over the epochs\n",
        "for ep in range(n_epochs):\n",
        "        \n",
        "    # Each epoch is a complete over the training data\n",
        "    for i in range(X_train.shape[0]):\n",
        "        \n",
        "        # pick one example\n",
        "        x = X_train[i]\n",
        "        y = y_train[i]\n",
        "#         print('new sample...')\n",
        "        # use it to update the weights\n",
        "        W,b,Wp,bp = update_weights(x,y,W,b,Wp,bp)\n",
        "#         print(W,b,Wp,bp)\n",
        "    # Calculate predictions for the full training and testing sample\n",
        "    y_pred_train = [dnn(x,W,b,Wp,bp)[0] for x in X_train]\n",
        "    y_pred = [dnn(x,W,b,Wp,bp)[0] for x in X_test]\n",
        "\n",
        "    # Calculate aver loss / example over the epoch\n",
        "    train_loss = sum((y_pred_train-y_train)**2) / y_train.shape[0]\n",
        "    test_loss = sum((y_pred-y_test)**2) / y_test.shape[0] \n",
        "    \n",
        "    # print some information\n",
        "    print(\"Epoch:\",ep, \"Train Loss:\", train_loss, \"Test Loss:\", test_loss)\n",
        "    \n",
        "    # and store the losses for later use\n",
        "    train_losses.append(train_loss)\n",
        "    test_losses.append(test_loss)\n",
        "    \n",
        "    \n",
        "# After the training:\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oG3P3cumbewn",
        "outputId": "0a1c7357-8ecb-4359-cf3a-a6c3196d01e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best loss: 0.6207440978455863 Final loss: 0.6207440978455863\n",
            "Correlation coefficient: 0.47201098289551785\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# Prepare scatter plot\n",
        "y_pred = [dnn(x,W,b,Wp,bp)[0] for x in X_test]\n",
        "\n",
        "print(\"Best loss:\", min(test_losses), \"Final loss:\", test_losses[-1])\n",
        "\n",
        "print(\"Correlation coefficient:\", np.corrcoef(y_pred,y_test)[0,1])\n",
        "plt.scatter(y_pred_train,y_train, alpha = 0.2)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.show()\n",
        "\n",
        "# Prepare and loss over time\n",
        "plt.plot(train_losses,label=\"train\")\n",
        "plt.plot(test_losses,label=\"test\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhI2SPE1bewn"
      },
      "source": [
        "This works worse than the linear regression ... \n",
        "well it does predict something so I guess now its bug-free\n",
        "the process is highly depedent on the learning rate :\n",
        "\n",
        "too large learning rates just converge to a single value ~6 as a prediction... \n",
        "smaller learning rates seem to do the trick better. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Nen08epkQB4"
      },
      "source": [
        "# Hint 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "escPUs3CkQB5"
      },
      "source": [
        "We want a network with one hidden layer. As activiation in the hidden layer $\\sigma$ we apply element-wise ReLu, while no activation is used for the output layer. The forward pass of the network then reads:\n",
        "$$\\hat{y}=\\mathbf{W}^{\\prime} \\sigma(\\mathbf{W} \\vec{x}+\\vec{b})+b^{\\prime}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DRDzLi2kQB5"
      },
      "source": [
        "# Hint 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GN01itNUkQB5"
      },
      "source": [
        "For the regression problem the objective function is the mean squared error between the prediction and the true label $y$: \n",
        "$$\n",
        "L=(\\hat{y}-y)^{2}\n",
        "$$\n",
        "\n",
        "Taking the partial derivatives - and diligently the applying chain rule - with respect to the different objects yields:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\frac{\\partial L}{\\partial b^{\\prime}} &=2(\\hat{y}-y) \\\\\n",
        "\\frac{\\partial L}{\\partial b_{k}} &=2(\\hat{y}-y) \\mathbf{W}_{k}^{\\prime} \\theta\\left(\\sum_{i} \\mathbf{W}_{i k} x_{i}+b_{k}\\right) \\\\\n",
        "\\frac{\\partial L}{\\partial \\mathbf{W}_{k}^{\\prime}} &=2(\\hat{y}-y) \\sigma\\left(\\sum_{i} \\mathbf{W}_{i k} x_{i}+b_{k}\\right) \\\\\n",
        "\\frac{\\partial L}{\\partial \\mathbf{W}_{k m}} &=2(\\hat{y}-y) \\mathbf{W}_{m}^{\\prime} \\theta\\left(\\sum_{i} \\mathbf{W}_{i m} x_{i}+b_{m}\\right) x_{k}\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Here, $\\Theta$ denotes the Heaviside step function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxQuegAEbewq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLNFJZoJbewq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}